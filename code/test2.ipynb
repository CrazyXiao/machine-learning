{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%-------------------------------\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from datetime import timedelta, datetime\n",
    "from sklearn.feature_selection import chi2, SelectPercentile\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from scipy import sparse\n",
    "from lightgbm import LGBMClassifier\n",
    "warnings.filterwarnings('ignore')\n",
    "# %%-------------------------------\n",
    "print('read data')\n",
    "df_test = pd.read_csv('data/round1_iflyad_anticheat_testdata_feature.txt', sep='\\t')\n",
    "df_train = pd.read_csv('data/round1_iflyad_anticheat_traindata.txt', sep='\\t')\n",
    "df_uni = pd.concat([df_train, df_test], ignore_index=True)\n",
    "df_uni['label'] = df_uni['label'].fillna(-1).astype(int)\n",
    "\n",
    "# %%-------------------------------\n",
    "\n",
    "cat_cols = ['pkgname', 'ver', 'adunitshowid', 'mediashowid', 'apptype', 'ip',\n",
    "            'reqrealip', 'city', 'province', 'adidmd5', 'imeimd5', 'idfamd5',\n",
    "            'openudidmd5', 'macmd5', 'dvctype', 'model', 'make', 'ntt',\n",
    "            'carrier', 'os', 'osv', 'orientation', 'lan', 'h', 'w', 'ppi']\n",
    "drop_cols = ['sid', 'label', 'nginxtime']\n",
    "\n",
    "# %%-------------------------------\n",
    "print('fill null')\n",
    "for cat_col in cat_cols:\n",
    "    if df_uni[cat_col].isnull().sum() > 0:\n",
    "        df_uni[cat_col].fillna('null_value', inplace=True)\n",
    "\n",
    "\n",
    "# %%-------------------------------\n",
    "def gen_value_counts(data, col):\n",
    "    print('value counts', col)\n",
    "    df_tmp = pd.DataFrame(data[col].value_counts().reset_index())\n",
    "    df_tmp.columns = [col, 'tmp']\n",
    "    r = pd.merge(data, df_tmp, how='left', on=col)['tmp']\n",
    "    return r.fillna(0)\n",
    "\n",
    "value_counts_col = ['pkgname', 'adunitshowid', 'ip', 'reqrealip',\n",
    "                    'adidmd5', 'imeimd5', 'idfamd5', 'macmd5']\n",
    "\n",
    "for col in value_counts_col:\n",
    "    df_uni['vc_' + col] = gen_value_counts(df_uni, col)\n",
    "\n",
    "# %%-------------------------------\n",
    "print('cut')\n",
    "def cut_col(data, col_name, cut_list):\n",
    "    print('cutting', col_name)\n",
    "\n",
    "    def _trans(array):\n",
    "        count = array['box_counts']\n",
    "        for box in cut_list:\n",
    "            if count <= box:\n",
    "                return 'count_' + str(box)\n",
    "        return array[col_name]\n",
    "\n",
    "    df_counts = pd.DataFrame(data[col_name].value_counts())\n",
    "    df_counts.columns = ['box_counts']\n",
    "    df_counts[col_name] = df_counts.index\n",
    "    df = pd.merge(data, df_counts, on=col_name, how='left')\n",
    "    column = df.apply(_trans, axis=1)\n",
    "    return column\n",
    "\n",
    "\n",
    "cut_col_dict = {\n",
    "    ('pkgname', 'ver', 'reqrealip', 'adidmd5',\n",
    "     'imeimd5', 'openudidmd5', 'macmd5', 'model', 'make'): [3],\n",
    "    ('ip',): [3, 5, 10],\n",
    "}\n",
    "\n",
    "for cut_cols, cut_list in cut_col_dict.items():\n",
    "    for col in cut_cols:\n",
    "        df_uni[col] = cut_col(df_uni, col, cut_list)\n",
    "\n",
    "# %%-------------------------------\n",
    "print('feature time')\n",
    "df_uni['datetime'] = pd.to_datetime(df_uni['nginxtime'] / 1000, unit='s') + timedelta(hours=8)\n",
    "df_uni['hour'] = df_uni['datetime'].dt.hour\n",
    "df_uni['day'] = df_uni['datetime'].dt.day - df_uni['datetime'].dt.day.min()\n",
    "\n",
    "cat_cols += ['hour']\n",
    "drop_cols += ['datetime', 'day']\n",
    "\n",
    "# %%-------------------------------\n",
    "print('post process')\n",
    "for col in cat_cols:\n",
    "    df_uni[col] = df_uni[col].map(dict(zip(df_uni[col].unique(), range(0, df_uni[col].nunique()))))\n",
    "\n",
    "all_train_index = (df_uni['day'] <= 6).values\n",
    "train_index     = (df_uni['day'] <= 5).values\n",
    "valid_index     = (df_uni['day'] == 6).values\n",
    "test_index      = (df_uni['day'] == 7).values\n",
    "train_label     = (df_uni['label']).values\n",
    "\n",
    "for col in drop_cols:\n",
    "    if col in df_uni.columns:\n",
    "        df_uni.drop([col], axis=1, inplace=True)\n",
    "\n",
    "ohe = OneHotEncoder()\n",
    "mtx_cat = ohe.fit_transform(df_uni[cat_cols])\n",
    "num_cols = list(set(df_uni.columns).difference(set(cat_cols)))\n",
    "mtx_num = sparse.csr_matrix(df_uni[num_cols].astype(float).values)\n",
    "mtx_uni = sparse.hstack([mtx_num, mtx_cat])\n",
    "mtx_uni = mtx_uni.tocsr()\n",
    "\n",
    "def col_filter(mtx_train, y_train, mtx_test, func=chi2, percentile=90):\n",
    "    feature_select = SelectPercentile(func, percentile=percentile)\n",
    "    feature_select.fit(mtx_train, y_train)\n",
    "    mtx_train = feature_select.transform(mtx_train)\n",
    "    mtx_test = feature_select.transform(mtx_test)\n",
    "    return mtx_train, mtx_test\n",
    "\n",
    "all_train_x, test_x = col_filter(\n",
    "    mtx_uni[all_train_index, :],\n",
    "    train_label[all_train_index],\n",
    "    mtx_uni[test_index, :]\n",
    ")\n",
    "\n",
    "\n",
    "train_x = all_train_x[train_index[:all_train_x.shape[0]], :]\n",
    "train_y = train_label[train_index]\n",
    "\n",
    "val_x = all_train_x[valid_index[:all_train_x.shape[0]], :]\n",
    "val_y = train_label[valid_index]\n",
    "\n",
    "# %%-------------------------------\n",
    "print('train')\n",
    "def lgb_f1(labels, preds):\n",
    "    score = f1_score(labels, np.round(preds))\n",
    "    return 'f1', score, True\n",
    "\n",
    "lgb = LGBMClassifier(random_seed=2019, n_jobs=-1, objective='binary',\n",
    "                     learning_rate=0.1, n_estimators=4000, num_leaves=64, max_depth=-1,\n",
    "                     min_child_samples=20, min_child_weight=9, subsample_freq=1,\n",
    "                     subsample=0.8, colsample_bytree=0.8, reg_alpha=1, reg_lambda=5)\n",
    "\n",
    "lgb.fit(\n",
    "    train_x,\n",
    "    train_y,\n",
    "    eval_set=[(train_x, train_y), (val_x, val_y)],\n",
    "    eval_names=['train', 'val'],\n",
    "    eval_metric=lgb_f1,\n",
    "    early_stopping_rounds=100,\n",
    "    verbose=10,\n",
    ")\n",
    "print('best score', lgb.best_score_)\n",
    "\n",
    "# %%-------------------------------\n",
    "print('predict')\n",
    "all_train_y = train_label[all_train_index]\n",
    "lgb.n_estimators = lgb.best_iteration_\n",
    "lgb.fit(all_train_x, all_train_y)\n",
    "test_y = lgb.predict(test_x)\n",
    "df_sub = pd.concat([df_test['sid'], pd.Series(test_y)], axis=1)\n",
    "df_sub.columns = ['sid', 'label']\n",
    "df_sub.to_csv('submit-{}.csv'.format(datetime.now().strftime('%m%d_%H%M%S')), sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "@author: shaowu\n",
    "注：此次会详细注释代码，往后都省略。\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import tqdm\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn import preprocessing\n",
    "from collections import Counter\n",
    "def one_hot_col(col):\n",
    "    '''标签编码'''\n",
    "    lbl = preprocessing.LabelEncoder()\n",
    "    lbl.fit(col)\n",
    "    return lbl\n",
    "def calculate_null(data,key,col):\n",
    "    '''\n",
    "    params:\n",
    "    data -- input data\n",
    "    key -- the key used for statistics\n",
    "    col -- the columns for statistics\n",
    "    return -- the data of DataFrame type, include two columns,\n",
    "              first columns id key,second is number of null\n",
    "    '''\n",
    "    return data.groupby(key,as_index=False)[col].agg({col+'_is_null':'count'})\n",
    "def xgb_model(new_train,y,new_test,lr):\n",
    "    '''定义模型'''\n",
    "    xgb_params = {'booster': 'gbtree',\n",
    "          'eta':lr, 'max_depth': 5, 'subsample': 0.8, 'colsample_bytree': 0.8, \n",
    "          'objective':'binary:logistic',\n",
    "          'eval_metric': 'auc',\n",
    "          'silent': True,\n",
    "          }\n",
    "    #skf=StratifiedKFold(y,n_folds=5,shuffle=True,random_state=2018)\n",
    "    skf=StratifiedKFold(n_splits=5,shuffle=True,random_state=42)\n",
    "    oof_xgb=np.zeros(new_train.shape[0])\n",
    "    prediction_xgb=np.zeros(new_test.shape[0])\n",
    "    for i,(tr,va) in enumerate(skf.split(new_train,y)):\n",
    "        print('fold:',i+1,'training')\n",
    "        dtrain = xgb.DMatrix(new_train[tr],y[tr])\n",
    "        dvalid = xgb.DMatrix(new_train[va],y[va])\n",
    "        watchlist = [(dtrain, 'train'), (dvalid, 'valid_data')]\n",
    "        bst = xgb.train(dtrain=dtrain, num_boost_round=30000, evals=watchlist, early_stopping_rounds=200, \\\n",
    "        verbose_eval=50, params=xgb_params)\n",
    "        oof_xgb[va] += bst.predict(xgb.DMatrix(new_train[va]), ntree_limit=bst.best_ntree_limit)\n",
    "        prediction_xgb += bst.predict(xgb.DMatrix(new_test), ntree_limit=bst.best_ntree_limit)\n",
    "    print('the roc_auc_score for train:',roc_auc_score(y,oof_xgb))\n",
    "    prediction_xgb/=5\n",
    "    return oof_xgb,prediction_xgb\n",
    "def lgb_model(new_train,y,new_test):\n",
    "    params = {\n",
    "    'learning_rate': 0.01,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'num_leaves': 1000,\n",
    "    'verbose': -1,\n",
    "    'max_depth': -1,\n",
    "  #  'reg_alpha':2.2,\n",
    "  #  'reg_lambda':1.4,\n",
    "    'seed':42,\n",
    "    }\n",
    "    #skf=StratifiedKFold(y,n_folds=5,shuffle=True,random_state=2018)\n",
    "    skf=StratifiedKFold(n_splits=5,shuffle=True,random_state=42)\n",
    "    oof_lgb=np.zeros(new_train.shape[0]) ##用于存放训练集概率，由每折验证集所得\n",
    "    prediction_lgb=np.zeros(new_test.shape[0])  ##用于存放测试集概率，k折最后要除以k取平均\n",
    "    feature_importance_df = pd.DataFrame() ##存放特征重要性，此处不考虑\n",
    "    for i,(tr,va) in enumerate(skf.split(new_train,y)):\n",
    "        print('fold:',i+1,'training')\n",
    "        dtrain = lgb.Dataset(new_train[tr],y[tr])\n",
    "        dvalid = lgb.Dataset(new_train[va],y[va],reference=dtrain)\n",
    "        ##训练：\n",
    "        bst = lgb.train(params, dtrain, num_boost_round=30000, valid_sets=dvalid, verbose_eval=400,early_stopping_rounds=200)\n",
    "        ##预测验证集：\n",
    "        oof_lgb[va] += bst.predict(new_train[va], num_iteration=bst.best_iteration)\n",
    "        ##预测测试集：\n",
    "        prediction_lgb += bst.predict(new_test, num_iteration=bst.best_iteration)\n",
    "        '''\n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = list(new_train.columns)\n",
    "        fold_importance_df[\"importance\"] = bst.feature_importance(importance_type='split', iteration=bst.best_iteration)\n",
    "        fold_importance_df[\"fold\"] = i + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "        '''\n",
    "    \n",
    "    print('the roc_auc_score for train:',roc_auc_score(y,oof_lgb)) ##线下auc评分\n",
    "    prediction_lgb/=5\n",
    "    return oof_lgb,prediction_lgb,feature_importance_df\n",
    "\n",
    "##读入测试数据：\n",
    "testdata= pd.read_csv(\"round1_iflyad_anticheat_testdata_feature.txt\",sep='\\t')\n",
    "testdata['label']=-1 ##测试集没有标签，可标记为-1\n",
    "\n",
    "testdata['begin_time']=testdata['sid'].apply(lambda x:int(x.split('-')[-1])) ##请求会话时间\n",
    "testdata['nginxtime-begin_time']=testdata['nginxtime']-testdata['begin_time'] ##请求会话时间 与 请求到达服务时间的差\n",
    "\n",
    "##读入训练数据：\n",
    "traindata= pd.read_csv(\"round1_iflyad_anticheat_traindata.txt\",sep='\\t')\n",
    "\n",
    "traindata['begin_time']=traindata['sid'].apply(lambda x:int(x.split('-')[-1]))\n",
    "traindata['nginxtime-begin_time']=traindata['nginxtime']-traindata['begin_time']\n",
    "\n",
    "##结合数据，方便提取特征：axis=0 纵向合并；axis=1 横向合并\n",
    "data=pd.concat([traindata,testdata],axis=0).reset_index(drop=True)\n",
    "\n",
    "print('the shape of data:',data.shpe)\n",
    "\n",
    "print(data.nunique()) ##返回每个字段的所有值组成集合的大小，即集合元素个数\n",
    "print(data[:5]) ##输出数据前5行\n",
    "z=calculate_null(testdata,'sid','ver') ##计算缺失值的，下面还没用到\n",
    "\n",
    "print('label distribution:\\n',traindata['label'].value_counts()) ##查看训练集标签分布\n",
    "\n",
    "object_cols=list(data.dtypes[data.dtypes==np.object].index) ##返回字段名为object类型的字段\n",
    "print(data.dtypes[data.dtypes==np.object].index) ##输出object类型的字段\n",
    "\n",
    "##本题所给时间戳为毫秒级，故需除以1000转换为秒级：时间戳转成日期格式\n",
    "print(time.strftime(\"%Y-%m-%d %H:%M:%S\",time.localtime(data['nginxtime'][0]/1000)))\n",
    "\n",
    "##对object类型的字段进行标签编码：\n",
    "for col in object_cols:\n",
    "    if col!='sid':\n",
    "        data[col]=one_hot_col(data[col].astype(str)).transform(data[col].astype(str))\n",
    "\n",
    "##划分数据：\n",
    "train=data[:traindata.shape[0]]\n",
    "label=train['label'].values\n",
    "test=data[traindata.shape[0]:].reset_index(drop=True)\n",
    "\n",
    "##模型训练预测：\n",
    "oof_lgb,prediction_lgb,feature_importance_df=\\\n",
    "      lgb_model(np.array(train.drop(['sid','label','nginxtime','ip','reqrealip','begin_time'],axis=1)),\\\n",
    "                label,\\\n",
    "                np.array(test.drop(['sid','label','nginxtime','ip','reqrealip','begin_time'],axis=1)))\n",
    "\n",
    "##保存结果：\n",
    "sub=test[['sid']]\n",
    "sub['label']=prediction_lgb\n",
    "sub['label']=sub['label'].apply(lambda x: 1 if x>0.5 else 0) ##∪概率大于0.5的置1，否则置0\n",
    "print('test pre_label distribution:\\n',sub['label'].value_counts()) ## 模型预测测试集的标签分布\n",
    "sub.to_csv('submit0704.csv',index=None) ##保存为submit0704.csv文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
