{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 推荐系统入门项目"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movies.dat  ratings.dat  README  u1.base  u1.test  users.dat\r\n"
     ]
    }
   ],
   "source": [
    "# 本项目使用的是MovieLens 1M 数据集，包含6000个用户在近4000部电影上的1亿条评论。\n",
    "#数据集分为三个文件：用户数据users.dat，电影数据movies.dat和评分数据ratings.dat\n",
    "! ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入相关包\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "import gc\n",
    "import math\n",
    "pd.set_option('display.float_format',lambda x : '%.3f' % x)\n",
    "plt.style.use('seaborn-dark') \n",
    "plt.rcParams['axes.unicode_minus']=False \n",
    "plt.rcParams['figure.figsize'] = (10.0, 5.0)\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_rating_data(path):\n",
    "    \"\"\"\n",
    "    读取评分数据并存储为csv文件\n",
    "    \"\"\"\n",
    "    f = pd.read_table(path,sep='::',names=['UserID','MovieID','Rating','Timestamp'])\n",
    "    # f.to_csv('ratings.csv',index=False)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/venv3/lib/python3.7/site-packages/ipykernel_launcher.py:5: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# 首先我们来看下数据\n",
    "# 评分数据分别有用户ID、电影ID、评分和时间戳等字段\n",
    "ratings = read_rating_data(\"data/ratings.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  MovieID  Rating  Timestamp\n",
       "0       1     1193       5  978300760\n",
       "1       1      661       3  978302109\n",
       "2       1      914       3  978301968\n",
       "3       1     3408       4  978300275\n",
       "4       1     2355       5  978824291"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-CF基于用户的协同过滤\n",
    "一般流程：\n",
    "1. 找到和目标用户兴趣相似的用户集合\n",
    "2. 找和这个集合中的用户喜欢的，且目标用户没有听说过的物品推荐给目标用户"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcute_similar(series1,series2):\n",
    "    \"\"\" \n",
    "        计算余弦相似度\n",
    "    \"\"\"\n",
    "    unionLen = len(set(series1) & set(series2))\n",
    "    if unionLen == 0: return 0.0\n",
    "    product = len(series1) * len(series2)\n",
    "    similarity = unionLen / math.sqrt(product)\n",
    "    return similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08465746311541544"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series1 = ratings[ratings['UserID'] == 1]['MovieID']\n",
    "series2 = ratings[ratings['UserID'] == 2]['MovieID']\n",
    "calcute_similar(series1, series2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_topk_sim(df,userid=1, k=10):\n",
    "    \"\"\" \n",
    "        计算与userid相似度最高topk\n",
    "    \"\"\"\n",
    "    target = df[df['UserID'] == userid]['MovieID']\n",
    "    other_users = set(df['UserID'].unique()) - set([userid])\n",
    "    others = [df[df['UserID'] == i]['MovieID'] for i in other_users]\n",
    "    similarlist = [calcute_similar(target,other) for other in others]\n",
    "    return pd.Series(similarlist,index=other_users).sort_values(ascending=False)[:k]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5343   0.389\n",
       "1481   0.385\n",
       "5190   0.377\n",
       "1283   0.365\n",
       "5705   0.334\n",
       "6006   0.321\n",
       "1858   0.319\n",
       "4718   0.316\n",
       "5762   0.316\n",
       "681    0.312\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_user_topk_sim(ratings, 1, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  MovieID  Rating  Timestamp\n",
       "0       1     1193       5  978300760\n",
       "1       1      661       3  978302109\n",
       "2       1      914       3  978301968\n",
       "3       1     3408       4  978300275\n",
       "4       1     2355       5  978824291"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcute_interest(frame, similarSeries, targetItemID):\n",
    "    \"\"\"\n",
    "        计算目标用户对目标物品的感兴趣程度\n",
    "    \"\"\"\n",
    "    similarUserID = similarSeries.index                                                 #和用户兴趣最相似的K个用户\n",
    "    similarUsers = [frame[frame['UserID'] == i] for i in similarUserID]                 #K个用户数据\n",
    "    similarUserValues = similarSeries.values                                            #用户和其他用户的兴趣相似度\n",
    "    UserInstItem = []\n",
    "    for u in similarUsers:                                                              #其他用户对物品的感兴趣程度\n",
    "        if targetItemID in u['MovieID'].values:\n",
    "            UserInstItem.append(u[u['MovieID']==targetItemID]['Rating'].values[0])\n",
    "        else:\n",
    "            UserInstItem.append(0)\n",
    "    interest = sum([similarUserValues[v]*UserInstItem[v]/5 for v in range(len(similarUserValues))])\n",
    "    return interest\n",
    "\n",
    "\n",
    "def calcuteItem(df, userid=1,k=10):\n",
    "    \"\"\" \n",
    "        推荐topk给用户\n",
    "    \"\"\"\n",
    "    similars = get_user_topk_sim(df, userid)\n",
    "    user_movie_ids = set(df[df['UserID'] == userid]['MovieID'])\n",
    "    other_movie_ids = set(df[df['UserID'] != userid]['MovieID'])\n",
    "    movie_ids = user_movie_ids ^ other_movie_ids #差集\n",
    "    interestlist = [calcute_interest(df, similars ,movie) for movie in movie_ids]\n",
    "    return pd.Series(interestlist, index=movie_ids).sort_values(ascending=False)[:k]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2081   2.642\n",
       "2078   2.356\n",
       "2096   2.164\n",
       "2085   2.088\n",
       "2080   1.864\n",
       "596    1.836\n",
       "364    1.696\n",
       "593    1.579\n",
       "2137   1.570\n",
       "480    1.564\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calcuteItem(ratings, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movies.dat  ratings.dat  README  u1.base  u1.test  users.dat\r\n"
     ]
    }
   ],
   "source": [
    "! ls data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def rmse(pred, actual):\n",
    "    '''计算预测结果的rmse'''\n",
    "    pred = pred[actual.nonzero()].flatten()\n",
    "    actual = actual[actual.nonzero()].flatten()\n",
    "    return np.sqrt(mean_squared_error(pred, actual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "title=['user_id', 'item_id', 'rating', 'timestamp']\n",
    "df = pd.read_csv(\"data/u1.base\",sep='\\t',names = title)\n",
    "test_df = pd.read_csv(\"data/u1.test\",sep='\\t',names = title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>874965758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>876893171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>878542960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>876893119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>889751712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0        1        1       5  874965758\n",
       "1        1        2       3  876893171\n",
       "2        1        3       4  878542960\n",
       "3        1        4       3  876893119\n",
       "4        1        5       3  889751712"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5., 3., 4., ..., 0., 0., 0.],\n",
       "       [4., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [5., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 5., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 构造评分矩阵\n",
    "ratings = np.zeros((np.max(df['user_id']), np.max(df['item_id'])))\n",
    "for row in df.itertuples():\n",
    "    ratings[row[1]-1,row[2]-1] = row[3]\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集矩阵密度为: 5.04%\n"
     ]
    }
   ],
   "source": [
    "# 可以看出来评分矩阵是个非常稀疏的矩阵，95%的数据都是空值\n",
    "sparsity = float(len(ratings.nonzero()[0]))\n",
    "sparsity /= (ratings.shape[0] * ratings.shape[1])\n",
    "sparsity *= 100\n",
    "print('训练集矩阵密度为: {:4.2f}%'.format(sparsity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(943, 1682)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/venv3/lib/python3.7/site-packages/ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in true_divide\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "all_mean = np.mean(ratings[ratings!=0])\n",
    "user_mean = sum(ratings.T)/sum((ratings!=0).T)\n",
    "item_mean = sum(ratings)/sum((ratings!=0))\n",
    "#用all_mean填充user_mean和item_mean可能存在的空值Nan\n",
    "user_mean = np.where(np.isnan(user_mean), all_mean, user_mean)\n",
    "item_mean = np.where(np.isnan(item_mean), all_mean, item_mean)\n",
    "# all_mean, user_mean, item_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_naive(user, item):\n",
    "    prediction = item_mean[item] + user_mean[user] - all_mean\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ 基线算法(baseline) ------\n",
      "载入测试集...\n",
      "测试集大小为 20000\n",
      "采用基线算法进行预测...\n",
      "测试结果的rmse为 0.9802\n"
     ]
    }
   ],
   "source": [
    "print('------ 基线算法(baseline) ------')\n",
    "print('载入测试集...')\n",
    "predictions = []\n",
    "targets = []\n",
    "print('测试集大小为 %d' % len(test_df))\n",
    "print('采用基线算法进行预测...')\n",
    "for row in test_df.itertuples():\n",
    "    user, item, actual = row[1]-1, row[2]-1, row[3]\n",
    "    predictions.append(predict_naive(user, item))\n",
    "    targets.append(actual)\n",
    "print('测试结果的rmse为 %.4f' % rmse(np.array(predictions), np.array(targets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ item-based协同过滤算法(相似度未归一化) ------\n"
     ]
    }
   ],
   "source": [
    "print('------ item-based协同过滤算法(相似度未归一化) ------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_similarity(ratings, kind, epsilon=1e-9):\n",
    "    '''利用余弦距离计算相似度'''\n",
    "    '''epsilon: 防止分母为0的异常'''\n",
    "    if kind == 'user':\n",
    "        sim = ratings.dot(ratings.T) + epsilon\n",
    "    elif kind == 'item':\n",
    "        sim = ratings.T.dot(ratings) + epsilon\n",
    "    norms = np.array([np.sqrt(np.diagonal(sim))])\n",
    "    return (sim / norms / norms.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "计算相似度矩阵...\n",
      "计算完成.\n",
      "相似度矩阵样例: (item-item)\n",
      "[[1.    0.358 0.309 0.374 0.234 0.088 0.542 0.41  0.422 0.235]\n",
      " [0.358 1.    0.222 0.419 0.283 0.084 0.335 0.286 0.193 0.12 ]\n",
      " [0.309 0.222 1.    0.263 0.144 0.078 0.308 0.187 0.289 0.148]\n",
      " [0.374 0.419 0.263 1.    0.273 0.1   0.402 0.4   0.339 0.185]\n",
      " [0.234 0.283 0.144 0.273 1.    0.017 0.276 0.185 0.206 0.04 ]\n",
      " [0.088 0.084 0.078 0.1   0.017 1.    0.123 0.07  0.14  0.139]\n",
      " [0.542 0.335 0.308 0.402 0.276 0.123 1.    0.336 0.446 0.256]\n",
      " [0.41  0.286 0.187 0.4   0.185 0.07  0.336 1.    0.32  0.201]\n",
      " [0.422 0.193 0.289 0.339 0.206 0.14  0.446 0.32  1.    0.213]\n",
      " [0.235 0.12  0.148 0.185 0.04  0.139 0.256 0.201 0.213 1.   ]]\n"
     ]
    }
   ],
   "source": [
    "print('计算相似度矩阵...')\n",
    "user_similarity = cal_similarity(ratings, kind='user')\n",
    "item_similarity = cal_similarity(ratings, kind='item')\n",
    "print('计算完成.')\n",
    "print('相似度矩阵样例: (item-item)')\n",
    "print(np.round_(item_similarity[:10,:10], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_itemCF(user, item, k=100):\n",
    "    '''item-based协同过滤算法,预测rating'''\n",
    "    nzero = ratings[user].nonzero()[0]\n",
    "    prediction = ratings[user, nzero].dot(item_similarity[item, nzero])\\\n",
    "                / sum(item_similarity[item, nzero])\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集大小为 20000\n",
      "采用item-based协同过滤算法进行预测...\n",
      "测试结果的rmse为 1.0331\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "targets = []\n",
    "print('测试集大小为 %d' % len(test_df))\n",
    "print('采用item-based协同过滤算法进行预测...')\n",
    "for row in test_df.itertuples():\n",
    "    user, item, actual = row[1]-1, row[2]-1, row[3]\n",
    "    predictions.append(predict_itemCF(user, item))\n",
    "    targets.append(actual)\n",
    "print('测试结果的rmse为 %.4f' % rmse(np.array(predictions), np.array(targets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ 结合基线算法的item-based协同过滤算法(相似度未归一化) ------\n"
     ]
    }
   ],
   "source": [
    "print('------ 结合基线算法的item-based协同过滤算法(相似度未归一化) ------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_itemCF_baseline(user, item, k=100):\n",
    "    '''结合baseline的item-basedCF算法,预测rating'''\n",
    "    nzero = ratings[user].nonzero()[0]\n",
    "    baseline = item_mean + user_mean[user] - all_mean\n",
    "    prediction = (ratings[user, nzero] - baseline[nzero]).dot(item_similarity[item, nzero])\\\n",
    "                / sum(item_similarity[item, nzero]) + baseline[item]\n",
    "    return prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集大小为 20000\n",
      "采用结合baseline的item-item协同过滤算法进行预测...\n",
      "测试结果的rmse为 0.9456\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "targets = []\n",
    "print('测试集大小为 %d' % len(test_df))\n",
    "print('采用结合baseline的item-item协同过滤算法进行预测...')\n",
    "for row in test_df.itertuples():\n",
    "    user, item, actual = row[1]-1, row[2]-1, row[3]\n",
    "    predictions.append(predict_itemCF_baseline(user, item))\n",
    "    targets.append(actual)\n",
    "print('测试结果的rmse为 %.4f' % rmse(np.array(predictions), np.array(targets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ user-based协同过滤算法(相似度未归一化) ------\n",
      "测试集大小为 20000\n",
      "采用user-user协同过滤算法进行预测...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/venv3/lib/python3.7/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试结果的rmse为 1.0264\n"
     ]
    }
   ],
   "source": [
    "print('------ user-based协同过滤算法(相似度未归一化) ------')\n",
    "\n",
    "def predict_userCF(user, item, k=100):\n",
    "    '''user-user协同过滤算法,预测rating'''\n",
    "    nzero = ratings[:,item].nonzero()[0]\n",
    "    baseline = user_mean + item_mean[item] - all_mean\n",
    "    prediction = ratings[nzero, item].dot(user_similarity[user, nzero])\\\n",
    "                / sum(user_similarity[user, nzero])\n",
    "    # 冷启动问题: 该item暂时没有评分\n",
    "    if np.isnan(prediction):\n",
    "        prediction = baseline[user]\n",
    "    return prediction\n",
    "\n",
    "\n",
    "predictions = []\n",
    "targets = []\n",
    "print('测试集大小为 %d' % len(test_df))\n",
    "print('采用user-user协同过滤算法进行预测...')\n",
    "\n",
    "for row in test_df.itertuples():\n",
    "    user, item, actual = row[1]-1, row[2]-1, row[3]\n",
    "    predictions.append(predict_userCF(user, item))\n",
    "    targets.append(actual)\n",
    "\n",
    "print('测试结果的rmse为 %.4f' % rmse(np.array(predictions), np.array(targets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ 结合基线算法的的user-user协同过滤算法(相似度未归一化) ------\n",
      "测试集大小为 20000\n",
      "采用结合baseline的user-user协同过滤算法进行预测...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/venv3/lib/python3.7/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试结果的rmse为 0.9679\n"
     ]
    }
   ],
   "source": [
    "print('------ 结合基线算法的的user-user协同过滤算法(相似度未归一化) ------')\n",
    "\n",
    "def predict_userCF_baseline(user, item, k=100):\n",
    "    '''结合baseline的user-user协同过滤算法,预测rating'''\n",
    "    nzero = ratings[:,item].nonzero()[0]\n",
    "    baseline = user_mean + item_mean[item] - all_mean\n",
    "    prediction = (ratings[nzero, item] - baseline[nzero]).dot(user_similarity[user, nzero])\\\n",
    "                / sum(user_similarity[user, nzero]) + baseline[user]\n",
    "    if np.isnan(prediction):\n",
    "        prediction = baseline[user]\n",
    "    return prediction\n",
    "\n",
    "predictions = []\n",
    "targets = []\n",
    "print('测试集大小为 %d' % len(test_df))\n",
    "print('采用结合baseline的user-user协同过滤算法进行预测...')\n",
    "\n",
    "for row in test_df.itertuples():\n",
    "    user, item, actual = row[1]-1, row[2]-1, row[3]\n",
    "    predictions.append(predict_userCF_baseline(user, item))\n",
    "    targets.append(actual)\n",
    "    \n",
    "print('测试结果的rmse为 %.4f' % rmse(np.array(predictions), np.array(targets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ 经过修正后的协同过滤 ------\n",
      "测试集大小为 20000\n",
      "采用结合baseline的item-based协同过滤算法进行预测...\n",
      "测试结果的rmse为 0.9455\n"
     ]
    }
   ],
   "source": [
    "print('------ 经过修正后的协同过滤 ------')\n",
    "def predict_biasCF(user, item, k=100):\n",
    "    '''结合基线算法的item-based CF算法,预测rating'''\n",
    "    nzero = ratings[user].nonzero()[0]\n",
    "    baseline = item_mean + user_mean[user] - all_mean\n",
    "    prediction = (ratings[user, nzero] - baseline[nzero]).dot(item_similarity[item, nzero])\\\n",
    "                / sum(item_similarity[item, nzero]) + baseline[item]\n",
    "    if prediction > 5:\n",
    "        prediction = 5\n",
    "    if prediction < 1:\n",
    "        prediciton = 1\n",
    "    return prediction\n",
    "\n",
    "predictions = []\n",
    "targets = []\n",
    "print('测试集大小为 %d' % len(test_df))\n",
    "print('采用结合baseline的item-based协同过滤算法进行预测...')\n",
    "for row in test_df.itertuples():\n",
    "    user, item, actual = row[1]-1, row[2]-1, row[3]\n",
    "    predictions.append(predict_biasCF(user, item))\n",
    "    targets.append(actual)\n",
    "\n",
    "print('测试结果的rmse为 %.4f' % rmse(np.array(predictions), np.array(targets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Top-k协同过滤(item-based + baseline)------\n",
      "测试集大小为 20000\n",
      "采用top K协同过滤算法进行预测...\n",
      "选取的K值为20.\n",
      "测试结果的rmse为 0.9309\n"
     ]
    }
   ],
   "source": [
    "print('------ Top-k协同过滤(item-based + baseline)------')\n",
    "def predict_topkCF(user, item, k=10):\n",
    "    '''top-k CF算法,以item-based协同过滤为基础，结合baseline,预测rating'''\n",
    "    nzero = ratings[user].nonzero()[0]\n",
    "    baseline = item_mean + user_mean[user] - all_mean\n",
    "    choice = nzero[item_similarity[item, nzero].argsort()[::-1][:k]]\n",
    "    prediction = (ratings[user, choice] - baseline[choice]).dot(item_similarity[item, choice])\\\n",
    "                / sum(item_similarity[item, choice]) + baseline[item]\n",
    "    if prediction > 5: prediction = 5\n",
    "    if prediction < 1: prediction = 1\n",
    "    return prediction \n",
    "\n",
    "predictions = []\n",
    "targets = []\n",
    "print('测试集大小为 %d' % len(test_df))\n",
    "print('采用top K协同过滤算法进行预测...')\n",
    "k = 20\n",
    "print('选取的K值为%d.' % k)\n",
    "for row in test_df.itertuples():\n",
    "    user, item, actual = row[1]-1, row[2]-1, row[3]\n",
    "    predictions.append(predict_topkCF(user, item, k))\n",
    "    targets.append(actual)\n",
    "\n",
    "print('测试结果的rmse为 %.4f' % rmse(np.array(predictions), np.array(targets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "计算归一化的相似度矩阵...\n",
      "计算完成.\n",
      "相似度矩阵样例: (item-item)\n",
      "[[ 1.     0.067  0.081  0.049  0.077  0.028  0.115  0.082  0.042  0.058]\n",
      " [ 0.067  1.    -0.002  0.127  0.054 -0.01   0.082  0.162 -0.045 -0.016]\n",
      " [ 0.081 -0.002  1.    -0.039  0.023  0.058  0.024 -0.036  0.     0.016]\n",
      " [ 0.049  0.127 -0.039  1.    -0.127  0.006  0.052  0.121  0.067  0.036]\n",
      " [ 0.077  0.054  0.023 -0.127  1.    -0.016  0.051  0.031  0.024 -0.046]\n",
      " [ 0.028 -0.01   0.058  0.006 -0.016  1.    -0.029 -0.01   0.013  0.035]\n",
      " [ 0.115  0.082  0.024  0.052  0.051 -0.029  1.     0.065  0.137  0.005]\n",
      " [ 0.082  0.162 -0.036  0.121  0.031 -0.01   0.065  1.     0.025  0.053]\n",
      " [ 0.042 -0.045  0.     0.067  0.024  0.013  0.137  0.025  1.    -0.013]\n",
      " [ 0.058 -0.016  0.016  0.036 -0.046  0.035  0.005  0.053 -0.013  1.   ]]\n"
     ]
    }
   ],
   "source": [
    "def cal_similarity_norm(ratings, kind, epsilon=1e-9):\n",
    "    '''采用归一化的指标:Pearson correlation coefficient'''\n",
    "    if kind == 'user':\n",
    "        # 对同一个user的打分归一化\n",
    "        rating_user_diff = ratings.copy()\n",
    "        for i in range(ratings.shape[0]):\n",
    "            nzero = ratings[i].nonzero()\n",
    "            rating_user_diff[i][nzero] = ratings[i][nzero] - user_mean[i]\n",
    "        sim = rating_user_diff.dot(rating_user_diff.T) + epsilon\n",
    "    elif kind == 'item':\n",
    "        # 对同一个item的打分归一化\n",
    "        rating_item_diff = ratings.copy()\n",
    "        for j in range(ratings.shape[1]):\n",
    "            nzero = ratings[:,j].nonzero()\n",
    "            rating_item_diff[:,j][nzero] = ratings[:,j][nzero] - item_mean[j]\n",
    "        sim = rating_item_diff.T.dot(rating_item_diff) + epsilon\n",
    "    norms = np.array([np.sqrt(np.diagonal(sim))])\n",
    "    return (sim / norms / norms.T)\n",
    "\n",
    "print('计算归一化的相似度矩阵...')\n",
    "user_similarity_norm = cal_similarity_norm(ratings, kind='user')\n",
    "item_similarity_norm = cal_similarity_norm(ratings, kind='item')\n",
    "print('计算完成.')\n",
    "print('相似度矩阵样例: (item-item)')\n",
    "print(np.round_(item_similarity_norm[:10,:10], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集大小为 20000\n",
      "采用归一化矩阵方法，结合其它trick进行预测...\n",
      "选取的K值为15.\n",
      "测试结果的rmse为 0.9388\n"
     ]
    }
   ],
   "source": [
    "def predict_norm_CF(user, item, k=20):\n",
    "    '''baseline + item-based + 皮尔森归一化'''\n",
    "    nzero = ratings[user].nonzero()[0]\n",
    "    baseline = item_mean + user_mean[user] - all_mean\n",
    "    choice = nzero[item_similarity_norm[item, nzero].argsort()[::-1][:k]]\n",
    "    prediction = (ratings[user, choice] - baseline[choice]).dot(item_similarity_norm[item, choice])\\\n",
    "                / sum(item_similarity_norm[item, choice]) + baseline[item]\n",
    "    if prediction > 5: prediction = 5\n",
    "    if prediction < 1: prediction = 1\n",
    "    return prediction \n",
    "\n",
    "predictions = []\n",
    "targets = []\n",
    "print('测试集大小为 %d' % len(test_df))\n",
    "print('采用归一化矩阵方法，结合其它trick进行预测...')\n",
    "k = 15\n",
    "print('选取的K值为%d.' % k)\n",
    "for row in test_df.itertuples():\n",
    "    user, item, actual = row[1]-1, row[2]-1, row[3]\n",
    "    predictions.append(predict_norm_CF(user, item, k))\n",
    "    targets.append(actual)\n",
    "\n",
    "print('测试结果的rmse为 %.4f' % rmse(np.array(predictions), np.array(targets)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
