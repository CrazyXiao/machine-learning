{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "\n",
    "# model\n",
    "import jieba\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', 150)\n",
    "pd.set_option('display.max_rows', 150)\n",
    "# pd.set_option('display.width', 1000)\n",
    "plt.rcParams['axes.unicode_minus']=False \n",
    "plt.rcParams['figure.figsize'] = (10.0, 5.0)\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文件目录\n",
    "path = \"/cos_person/zhaopin/data/\"\n",
    "\n",
    "salary_dict = {'0000000000': np.nan, '0000001000': 1, '0100002000': 2, '0200104000': 3, '0400106000': 4,\n",
    "               '0600108000': 5, '0800110000': 6, '1000115000': 7, '1500120000': 8, '1500125000': 9, '2000130000': 10,\n",
    "               '2500199999': 11, '2500135000': 11, '3000150000': 12, '3500150000': 12, '5000170000': 13,\n",
    "               '70001100000': 14, '100001150000': 15, '-': np.nan}\n",
    "salary_max_dict = {'0000000000': np.nan, '0000001000': 1000, '0100002000': 2000, '0200104000': 4000, '0400106000': 6000,\n",
    "                   '0600108000': 8000, '0800110000': 10000, '1000115000': 15000, '1500120000': 20000,\n",
    "                   '1500125000': 25000, '2000130000': 30000,\n",
    "                   '2500199999': 35000, '2500135000': 35000, '3000150000': 50000, '3500150000': 50000,\n",
    "                   '5000170000': 70000,\n",
    "                   '70001100000': 100000, '100001150000': 150000, '-': np.nan}\n",
    "salary_min_dict = {'0000000000': np.nan, '0000001000': 0, '0100002000': 1000, '0200104000': 2000, '0400106000': 4000,\n",
    "                   '0600108000': 6000, '0800110000': 8000, '1000115000': 10000, '1500120000': 15000,\n",
    "                   '1500125000': 15000, '2000130000': 20000,\n",
    "                   '2500199999': 25000, '2500135000': 25000, '3000150000': 30000, '3500150000': 35000,\n",
    "                   '5000170000': 50000,\n",
    "                   '70001100000': 70000, '100001150000': 100000, '-': np.nan}\n",
    "degress_dict = {'初中': 1, '中专': 2, '中技': 2, '高中': 2, '大专': 3, r'\\N': 0, '请选择': 0,\n",
    "                '本科': 4, '硕士': 5, 'MBA': 5, 'EMBA': 5, '博士': 6, '其他': -1}\n",
    "job_min_year_dict = {-1: 0, 103: 1, 305: 3, 510: 5, 1099: 10, 1: 1, 0: 0, 399: 3, 599: 5, 299: 2, 199: 1, 110: 1}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义评测函数\n",
    "def _map_score(df):\n",
    "    \"\"\"\n",
    "        评测\n",
    "    \"\"\"\n",
    "    map_res = 0\n",
    "    map_dict = {'satisfied':0.7,'delivered':0.3}\n",
    "    for item in ['satisfied','delivered']:\n",
    "        tmp = df.copy()\n",
    "        tmp['rank'] = tmp.groupby(['user_id'])['score'].rank(ascending=False,method='first')\n",
    "        tmp_score = tmp[tmp[item]==1]\n",
    "        tmp_score['rank_1'] = tmp_score.groupby(['user_id'])['rank'].rank(ascending=True,method='first')\n",
    "        tmp_score['AP'] = tmp_score['rank_1'] / tmp_score['rank']\n",
    "        _map = tmp_score.groupby(['user_id'])['AP'].mean().reset_index()['AP'].mean()\n",
    "        map_res = map_res + _map * map_dict[item]\n",
    "    return map_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 173315: expected 18 fields, saw 20\\n'\n"
     ]
    }
   ],
   "source": [
    "def load_raw_data(data_path):\n",
    "    # load train_user\n",
    "    raw_user_dtype = {'live_city_id': object, 'desire_jd_salary_id': object, 'cur_salary_id': object, 'birthday': np.int16,\n",
    "                      'start_work_date': object, }\n",
    "    raw_user = pd.read_csv(data_path + 'table1_user', delimiter='\\t', error_bad_lines=False, dtype=raw_user_dtype)\n",
    "    # load train_job\n",
    "    raw_job_dtype = {'city': object, 'require_nums': np.int16, 'max_salary': np.int32, 'min_salary': np.int32,\n",
    "                     'start_date': object, 'end_date': object, 'raw_job': np.int16, 'is_travel': np.int16,\n",
    "                     'min_years': np.int16, }\n",
    "    raw_job = pd.read_csv(data_path + 'table2_jd', delimiter='\\t', error_bad_lines=False, dtype=raw_job_dtype)\n",
    "    # load train_action\n",
    "    raw_action_dtype = {'browsed': np.int16, 'delivered': np.int16, 'satisfied': np.int16,}\n",
    "    raw_action = pd.read_csv(data_path + 'table3_action', delimiter='\\t', error_bad_lines=False, dtype=raw_action_dtype)\n",
    "    # load test_user\n",
    "    test_user_dtype = {'live_city_id': object, 'desire_jd_salary_id': object, 'cur_salary_id': object, 'birthday': np.int16,\n",
    "                       'start_work_date': object}\n",
    "    test_user = pd.read_csv(data_path + \"user_ToBePredicted\", delimiter=\"\\t\", error_bad_lines=False, dtype=test_user_dtype)\n",
    "    # load test_action\n",
    "    test_action = pd.read_csv(data_path + \"zhaopin_round1_user_exposure_B_20190819\", delim_whitespace=True)\n",
    "    return raw_user, raw_job, raw_action, test_user, test_action\n",
    "\n",
    "# 读取数据\n",
    "train_user, train_job,train_action, test_user, test_action = load_raw_data(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_str(x, pattern = [',', ' ', '，', ')', '）', '(', '（', '|'], sep='/'):\n",
    "    if pd.isna(x):\n",
    "        return x\n",
    "    else:\n",
    "        for p in pattern:\n",
    "            x = x.replace(p, sep)\n",
    "        return set(x.split(sep))\n",
    "\n",
    "def del_key(x, keys):\n",
    "    if pd.isna(x):\n",
    "        return x\n",
    "    for k in keys:\n",
    "        x = x.replace(k, '')\n",
    "    return x    \n",
    "\n",
    "def clean_user(raw_user):\n",
    "    user = raw_user.copy()\n",
    "    user.set_index('user_id', inplace=True)\n",
    "    tmp = user['desire_jd_city_id'].str.split(',')\n",
    "    user['desire_jd_city_id_0'] = tmp.apply(lambda x: x[0])\n",
    "    user['desire_jd_city_id_1'] = tmp.apply(lambda x: x[1])\n",
    "    user['desire_jd_city_id_2'] = tmp.apply(lambda x: x[2])\n",
    "    user['desire_jd_industry_set'] = user['desire_jd_industry_id'].apply(split_str)\n",
    "    user['desire_jd_type_set'] = user['desire_jd_type_id'].apply(split_str)\n",
    "    user['desire_jd_max_salary'] = user['desire_jd_salary_id'].apply(lambda x: salary_max_dict[x])\n",
    "    user['desire_jd_min_salary'] = user['desire_jd_salary_id'].apply(lambda x: salary_min_dict[x])\n",
    "    user['desire_jd_salary_id'] = user['desire_jd_salary_id'].apply(lambda x: salary_dict[x])\n",
    "    user['cur_industry_set'] = user['cur_industry_id'].apply(split_str)\n",
    "    user['cur_jd_type_set'] = user['cur_jd_type'].apply(split_str)\n",
    "    user['cur_jd_max_salary'] = user['cur_salary_id'].apply(lambda x: salary_max_dict[x])\n",
    "    user['cur_jd_min_salary'] = user['cur_salary_id'].apply(lambda x: salary_min_dict[x])\n",
    "    user['cur_salary_id'] = user['cur_salary_id'].apply(lambda x: salary_dict[x])\n",
    "    user['cur_degree_id'] = user['cur_degree_id'].apply(lambda x: np.nan if pd.isna(x) else degress_dict[x.strip()])\n",
    "    user['start_work_date'] = user['start_work_date'].apply(lambda x: np.nan if x == '-' else int(x))\n",
    "    keys = ['自我评价|', '操作|', '实习|', '申请|', '资金|', '政策|', '知识|', '大型|', '发布|', '变更|', '传达|', '发光|', '方法论|']\n",
    "    user['experience_drop_keys'] = user['experience'].apply(del_key, **{'keys': keys})\n",
    "    user['experience_set'] = user['experience_drop_keys'].apply(split_str, **{'pattern': [], 'sep': '|'})\n",
    "    return user\n",
    "\n",
    "def clean_job(raw_job, raw_action):\n",
    "    job = raw_job.copy()\n",
    "    jd_title_list = job['jd_title'].apply(jieba.lcut)\n",
    "    job['jd_title_set'] = jd_title_list.apply(lambda x: set([s for s in x if len(s) > 1]))\n",
    "    job.drop(columns=['company_name'], inplace=True)\n",
    "    job['jd_sub_type_set'] = job['jd_sub_type'].apply(split_str)\n",
    "    date_nan = '18000101'\n",
    "    date_nan_datetime = pd.to_datetime(date_nan)\n",
    "    job.loc[job['start_date'] == '\\\\N', 'start_date'] = date_nan\n",
    "    job['start_date'] = pd.to_datetime(job['start_date'])\n",
    "    job.loc[job['start_date'] == date_nan_datetime, 'start_date'] = np.nan\n",
    "    job.loc[job['end_date'] == '\\\\N', 'end_date'] = date_nan\n",
    "    job['end_date'] = pd.to_datetime(job['end_date'])\n",
    "    job.loc[job['end_date'] == date_nan_datetime, 'end_date'] = np.nan\n",
    "    job.loc[job['is_travel'] == 2, 'is_travel'] = np.nan\n",
    "    job['min_years'] = job['min_years'].apply(lambda x: job_min_year_dict[x])\n",
    "    job['key_set'] = job['key'].apply(split_str, **{'sep': '|'})\n",
    "    job['min_edu_level'] = job['min_edu_level'].apply(lambda x: np.nan if pd.isna(x) else degress_dict[x.strip()])\n",
    "    job.drop(columns=['max_edu_level', 'is_mangerial', 'resume_language_required'], inplace=True)\n",
    "    jd_no_count = raw_action.groupby('jd_no')[['browsed', 'delivered', 'satisfied']].sum()\n",
    "    jd_no_count.columns = ['browsed_count', 'delivered_count', 'satisfied_count']\n",
    "    job = pd.merge(job, jd_no_count, left_on='jd_no', right_index=True, how='left')\n",
    "    job.set_index('jd_no', inplace=True)\n",
    "    return job\n",
    "\n",
    "def train_action_generate(raw_action):\n",
    "    '''\n",
    "        表示招聘者对应职位的打分情况\n",
    "    '''\n",
    "    action = raw_action.groupby(['user_id', 'jd_no'])[['delivered', 'satisfied']].max()\n",
    "    action.reset_index(inplace=True)\n",
    "    action['y'] = action['delivered'] * 0.3 + action['satisfied'] * 0.7\n",
    "    action.set_index(['user_id', 'jd_no'], inplace=True)\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feats_generate(action, user, job):\n",
    "    # 将简历信息和职位信息合并到action\n",
    "    action = pd.merge(action, user, left_index=True, right_index=True, how='left')\n",
    "    action = pd.merge(action, job, left_index=True, right_index=True, how='left')\n",
    "    if 'y' in action.columns:\n",
    "        action_feats = action[['y', 'delivered', 'satisfied']]\n",
    "    else:\n",
    "        action_feats = action[[]]\n",
    "\n",
    "    # 城市相关特征\n",
    "    \n",
    "    big_city_dict = defaultdict(lambda: 0) # 是否属于一线城市\n",
    "    big_city_dict['530'] = 1\n",
    "    big_city_dict['801'] = 1\n",
    "    big_city_dict['538'] = 1\n",
    "    big_city_dict['719'] = 1\n",
    "    big_city_dict['854'] = 1\n",
    "    \n",
    "    action_feats['feat_live_city_is_big'] = action['live_city_id'].apply(lambda x: big_city_dict[x])\n",
    "    action_feats['feat_live_city_desire_0'] = (action['live_city_id'] == action['desire_jd_city_id_0'])*1\n",
    "    action_feats['feat_live_city_desire_1'] = (action['live_city_id'] == action['desire_jd_city_id_1'])*1\n",
    "    action_feats['feat_live_city_desire_2'] = (action['live_city_id'] == action['desire_jd_city_id_2'])*1\n",
    "    action_feats['feat_live_ctiy_desire'] = ((action_feats['feat_live_city_desire_0'] + \\\n",
    "                                             action_feats['feat_live_city_desire_1'] + \\\n",
    "                                             action_feats['feat_live_city_desire_2']) >= 1)*1\n",
    "    action_feats['feat_job_city_is_big'] = action['city'].apply(lambda x: big_city_dict[x])\n",
    "    action_feats['feat_job_city_desire_0_is_big'] = action['desire_jd_city_id_0'].apply(lambda x: big_city_dict[x])\n",
    "    action_feats['feat_city_live_job'] = (action['live_city_id'] == action['city'])*1\n",
    "    action_feats['feat_job_city_desire_0'] = (action['city'] == action['desire_jd_city_id_0'])*1\n",
    "    action_feats['feat_job_city_desire_1'] = (action['city'] == action['desire_jd_city_id_1'])*1\n",
    "    action_feats['feat_job_city_desire_2'] = (action['city'] == action['desire_jd_city_id_2'])*1\n",
    "    action_feats['feat_job_ctiy_desire'] = ((action_feats['feat_job_city_desire_0'] + \\\n",
    "                                             action_feats['feat_job_city_desire_1'] + \\\n",
    "                                             action_feats['feat_job_city_desire_2']) >= 1)*1\n",
    "    action_feats['feat_desire_jd_city_count'] = (action['desire_jd_city_id_0'] != '-')*1 +  \\\n",
    "                                           (action['desire_jd_city_id_1'] != '-')*1 + \\\n",
    "                                           (action['desire_jd_city_id_2'] != '-')*1\n",
    "    # About desire and current industry\n",
    "    action_feats['feat_desire_indu_len'] = action['desire_jd_industry_set'].apply(find_len_set)\n",
    "    action_feats['feat_cur_indu_len'] = action['cur_industry_set'].apply(find_len_set)\n",
    "    action_feats['feat_desire_cur_indu_len'] = (action['desire_jd_industry_set']-(action['desire_jd_industry_set']-action['cur_industry_set'])).apply(find_len_set)\n",
    "    action_feats['feat_cur_desire_indu_ratio'] = action_feats['feat_desire_cur_indu_len']/(action['desire_jd_industry_set'].apply(find_len_set) + 0.0)\n",
    "    action_feats['feat_desire_cur_indu_ratio'] = action_feats['feat_desire_cur_indu_len']/(action['cur_industry_set'].apply(find_len_set) + 0.0)\n",
    "    action_feats['feat_desire_cur_indu_jaccard'] = action_feats['feat_desire_cur_indu_len'] / (\n",
    "                (action['desire_jd_industry_set'] - action['cur_industry_set']).apply(find_len_set) + (\n",
    "                    action['cur_industry_set'] - action['desire_jd_industry_set']).apply(find_len_set) + action_feats[\n",
    "                    'feat_desire_cur_indu_len'] + 0.0)\n",
    "\n",
    "    # About desire and current type\n",
    "    action_feats['feat_desire_jd_type_len'] = action['desire_jd_type_set'].apply(find_len_set)\n",
    "    action_feats['feat_cur_jd_type_len'] = action['cur_jd_type_set'].apply(find_len_set)\n",
    "    action_feats['feat_desire_cur_type_len'] = (action['desire_jd_type_set']-(action['desire_jd_type_set']-action['cur_jd_type_set'])).apply(find_len_set)\n",
    "    action_feats['feat_cur_desire_type_len_ratio'] = action_feats['feat_desire_cur_type_len']/(action['desire_jd_type_set'].apply(find_len_set) + 0.0)\n",
    "    action_feats['feat_desire_cur_type_len_ratio'] = action_feats['feat_desire_cur_type_len']/(action['cur_jd_type_set'].apply(find_len_set) + 0.0)\n",
    "    action_feats['feat_desire_cur_type_jaccard'] = action_feats['feat_desire_cur_type_len'] / (\n",
    "                (action['desire_jd_type_set'] - action['cur_jd_type_set']).apply(find_len_set) + (\n",
    "                    action['cur_jd_type_set'] - action['desire_jd_type_set']).apply(find_len_set) + action_feats[\n",
    "                    'feat_desire_cur_type_len'] + 0.0)\n",
    "\n",
    "    # About titles of job and users' desire and current industry and type\n",
    "    action_feats['feat_jd_title_len'] = action['jd_title_set'].apply(find_len_set)\n",
    "    action_feats['feat_desire_indu_title_len'] = (action['desire_jd_industry_set']-(action['desire_jd_industry_set']-action['jd_title_set'])).apply(find_len_set)\n",
    "    action_feats['feat_title_desire_indu_ratio'] = action_feats['feat_desire_indu_title_len']/(action['desire_jd_industry_set'].apply(find_len_set) + 0.0)\n",
    "    action_feats['feat_desire_indu_title_ratio'] = action_feats['feat_desire_indu_title_len']/(action['jd_title_set'].apply(find_len_set) + 0.0)\n",
    "    action_feats['feat_desire_indu_title_jaccard'] = action_feats['feat_desire_indu_title_len'] / (\n",
    "                (action['desire_jd_industry_set'] - action['jd_title_set']).apply(find_len_set) + (\n",
    "                    action['jd_title_set'] - action['desire_jd_industry_set']).apply(find_len_set) + action_feats[\n",
    "                    'feat_desire_indu_title_len'] + 0.0)\n",
    "\n",
    "    action_feats['feat_cur_indu_title_len'] = (action['cur_industry_set']-(action['cur_industry_set']-action['jd_title_set'])).apply(find_len_set)\n",
    "    action_feats['feat_title_cur_indu_ratio'] = action_feats['feat_cur_indu_title_len']/(action['cur_industry_set'].apply(find_len_set) + 0.0)\n",
    "    action_feats['feat_cur_indu_title_ratio'] = action_feats['feat_cur_indu_title_len']/(action['jd_title_set'].apply(find_len_set) + 0.0)\n",
    "    action_feats['feat_cur_indu_title_jaccard'] = action_feats['feat_cur_indu_title_len'] / (\n",
    "                (action['cur_industry_set'] - action['jd_title_set']).apply(find_len_set) + (\n",
    "                    action['jd_title_set'] - action['cur_industry_set']).apply(find_len_set) + action_feats[\n",
    "                    'feat_cur_indu_title_len'] + 0.0)\n",
    "\n",
    "\n",
    "    action_feats['feat_desire_type_title_len'] = (action['desire_jd_type_set']-(action['desire_jd_type_set']-action['jd_title_set'])).apply(find_len_set)\n",
    "    action_feats['feat_title_desire_type_ratio'] = action_feats['feat_desire_type_title_len']/(action['desire_jd_type_set'].apply(find_len_set) + 0.0)\n",
    "    action_feats['feat_desire_type_title_ratio'] = action_feats['feat_desire_type_title_len']/(action['jd_title_set'].apply(find_len_set) + 0.0)\n",
    "    action_feats['feat_desire_type_title_jaccard'] = action_feats['feat_desire_type_title_len'] / (\n",
    "                (action['desire_jd_type_set'] - action['jd_title_set']).apply(find_len_set) + (\n",
    "                    action['jd_title_set'] - action['desire_jd_type_set']).apply(find_len_set) + action_feats[\n",
    "                    'feat_desire_type_title_len'] + 0.0)\n",
    "\n",
    "\n",
    "    action_feats['feat_cur_type_title_len'] = (action['cur_jd_type_set']-(action['cur_jd_type_set']-action['jd_title_set'])).apply(find_len_set)\n",
    "    action_feats['feat_title_cur_type_ratio'] = action_feats['feat_cur_type_title_len']/(action['cur_jd_type_set'].apply(find_len_set) + 0.0)\n",
    "    action_feats['feat_cur_type_title_ratio'] = action_feats['feat_cur_type_title_len']/(action['jd_title_set'].apply(find_len_set) + 0.0)\n",
    "    action_feats['feat_cur_type_title_jaccard'] = action_feats['feat_cur_type_title_len'] / (\n",
    "                (action['cur_jd_type_set'] - action['jd_title_set']).apply(find_len_set) + (\n",
    "                    action['jd_title_set'] - action['cur_jd_type_set']).apply(find_len_set) + action_feats[\n",
    "                    'feat_cur_type_title_len'] + 0.0)\n",
    "\n",
    "    # About sub_type of job and users' desire and current industry and type\n",
    "    action_feats['feat_jd_sub_type_len'] = action['jd_sub_type_set'].apply(find_len_set)\n",
    "    action_feats['feat_desire_indu_job_type_len'] = (action['desire_jd_industry_set']-(action['desire_jd_industry_set']-action['jd_sub_type_set'])).apply(find_len_set)\n",
    "    action_feats['feat_job_type_desire_indu_ratio'] = action_feats['feat_desire_indu_job_type_len']/(action['desire_jd_industry_set'].apply(find_len_set) + 0.0)\n",
    "    action_feats['feat_desire_indu_job_type_ratio'] = action_feats['feat_desire_indu_job_type_len']/(action['jd_sub_type_set'].apply(find_len_set) + 0.0)\n",
    "    action_feats['feat_desire_indu_job_type_jaccard'] = action_feats['feat_desire_indu_job_type_len'] / (\n",
    "                (action['desire_jd_industry_set'] - action['jd_sub_type_set']).apply(find_len_set) + (\n",
    "                    action['jd_sub_type_set'] - action['desire_jd_industry_set']).apply(find_len_set) + action_feats[\n",
    "                    'feat_desire_indu_job_type_len'] + 0.0)\n",
    "\n",
    "\n",
    "    action_feats['feat_cur_indu_job_type_len'] = (action['cur_industry_set']-(action['cur_industry_set']-action['jd_sub_type_set'])).apply(find_len_set)\n",
    "    action_feats['feat_job_type_cur_indu_ratio'] = action_feats['feat_cur_indu_job_type_len']/(action['cur_industry_set'].apply(find_len_set) + 0.0)\n",
    "    action_feats['feat_cur_indu_job_type_ratio'] = action_feats['feat_cur_indu_job_type_len']/(action['jd_sub_type_set'].apply(find_len_set) + 0.0)\n",
    "    action_feats['feat_cur_indu_job_type_jaccard'] = action_feats['feat_cur_indu_job_type_len'] / (\n",
    "                (action['cur_industry_set'] - action['jd_sub_type_set']).apply(find_len_set) + (\n",
    "                    action['jd_sub_type_set'] - action['cur_industry_set']).apply(find_len_set) + action_feats[\n",
    "                    'feat_cur_indu_job_type_len'] + 0.0)\n",
    "\n",
    "\n",
    "    action_feats['feat_desire_type_job_type_len'] = (action['desire_jd_type_set']-(action['desire_jd_type_set']-action['jd_sub_type_set'])).apply(find_len_set)\n",
    "    action_feats['feat_job_type_desire_type_ratio'] = action_feats['feat_desire_type_job_type_len']/(action['desire_jd_type_set'].apply(find_len_set) + 0.0)\n",
    "    action_feats['feat_desire_type_job_type_ratio'] = action_feats['feat_desire_type_job_type_len']/(action['jd_sub_type_set'].apply(find_len_set) + 0.0)\n",
    "    action_feats['feat_desire_type_job_type_jaccard'] = action_feats['feat_desire_type_job_type_len'] / (\n",
    "                (action['desire_jd_type_set'] - action['jd_sub_type_set']).apply(find_len_set) + (\n",
    "                    action['jd_sub_type_set'] - action['desire_jd_type_set']).apply(find_len_set) + action_feats[\n",
    "                    'feat_desire_type_job_type_len'] + 0.0)\n",
    "\n",
    "\n",
    "    action_feats['feat_cur_type_job_type_len'] = (action['cur_jd_type_set']-(action['cur_jd_type_set']-action['jd_sub_type_set'])).apply(find_len_set)\n",
    "    action_feats['feat_job_type_cur_type_ratio'] = action_feats['feat_cur_type_job_type_len']/(action['cur_jd_type_set'].apply(find_len_set) + 0.0)\n",
    "    action_feats['feat_cur_type_job_type_ratio'] = action_feats['feat_cur_type_job_type_len']/(action['jd_sub_type_set'].apply(find_len_set) + 0.0)\n",
    "    action_feats['feat_cur_type_job_type_jaccard'] = action_feats['feat_cur_type_job_type_len'] / (\n",
    "                (action['cur_jd_type_set'] - action['jd_sub_type_set']).apply(find_len_set) + (\n",
    "                    action['jd_sub_type_set'] - action['cur_jd_type_set']).apply(find_len_set) + action_feats[\n",
    "                    'feat_cur_type_job_type_len'] + 0.0)\n",
    "\n",
    "\n",
    "    # About job key and users' desire and current industry and type\n",
    "    action_feats['feat_key_set_len'] = action['key_set'].apply(find_len_set)\n",
    "    action_feats['feat_desire_indu_job_key_len'] = (action['desire_jd_industry_set']-(action['desire_jd_industry_set']-action['key_set'])).apply(find_len_set)\n",
    "    action_feats['feat_job_key_desire_indu_ratio'] = action_feats['feat_desire_indu_job_key_len']/(action['desire_jd_industry_set'].apply(find_len_set) + 0.00001)\n",
    "    action_feats['feat_desire_indu_job_key_ratio'] = action_feats['feat_desire_indu_job_key_len']/(action['key_set'].apply(find_len_set) + 0.00001)\n",
    "    action_feats['feat_desire_indu_job_key_jaccard'] = action_feats['feat_desire_indu_job_key_len'] / (\n",
    "                (action['desire_jd_industry_set'] - action['key_set']).apply(find_len_set) + (\n",
    "                    action['key_set'] - action['desire_jd_industry_set']).apply(find_len_set) + action_feats[\n",
    "                    'feat_cur_type_job_type_len'] + 0.0)\n",
    "\n",
    "\n",
    "    action_feats['feat_cur_indu_job_key_len'] = (action['cur_industry_set']-(action['cur_industry_set']-action['key_set'])).apply(find_len_set)\n",
    "    action_feats['feat_job_key_cur_indu_ratio'] = action_feats['feat_cur_indu_job_key_len']/(action['cur_industry_set'].apply(find_len_set) + 0.00001)\n",
    "    action_feats['feat_cur_indu_job_key_ratio'] = action_feats['feat_cur_indu_job_key_len']/(action['key_set'].apply(find_len_set) + 0.00001)\n",
    "    action_feats['feat_cur_indu_job_key_jaccard'] = action_feats['feat_cur_indu_job_key_len'] / (\n",
    "                (action['cur_industry_set'] - action['key_set']).apply(find_len_set) + (\n",
    "                    action['key_set'] - action['cur_industry_set']).apply(find_len_set) + action_feats[\n",
    "                    'feat_cur_indu_job_key_len'] + 0.0)\n",
    "\n",
    "\n",
    "    action_feats['feat_desire_type_job_key_len'] = (action['desire_jd_type_set']-(action['desire_jd_type_set']-action['key_set'])).apply(find_len_set)\n",
    "    action_feats['feat_job_key_desire_type_ratio'] = action_feats['feat_desire_type_job_key_len']/(action['desire_jd_type_set'].apply(find_len_set) + 0.0)\n",
    "    action_feats['feat_desire_type_job_key_ratio'] = action_feats['feat_desire_type_job_key_len']/(action['key_set'].apply(find_len_set) + 0.0)\n",
    "    action_feats['feat_desire_type_job_key_jaccard'] = action_feats['feat_desire_type_job_key_len'] / (\n",
    "                (action['desire_jd_type_set'] - action['key_set']).apply(find_len_set) + (\n",
    "                    action['key_set'] - action['desire_jd_type_set']).apply(find_len_set) + action_feats[\n",
    "                    'feat_desire_type_job_key_len'] + 0.0)\n",
    "\n",
    "\n",
    "    action_feats['feat_cur_type_job_key_len'] = (action['cur_jd_type_set']-(action['cur_jd_type_set']-action['key_set'])).apply(find_len_set)\n",
    "    action_feats['feat_job_key_cur_type_ratio'] = action_feats['feat_cur_type_job_key_len']/(action['cur_jd_type_set'].apply(find_len_set) + 0.0)\n",
    "    action_feats['feat_cur_type_job_key_ratio'] = action_feats['feat_cur_type_job_key_len']/(action['key_set'].apply(find_len_set) + 0.0)\n",
    "    action_feats['feat_cur_type_job_key_jaccard'] = action_feats['feat_cur_type_job_key_len'] / (\n",
    "                (action['cur_jd_type_set'] - action['key_set']).apply(find_len_set) + (\n",
    "                    action['key_set'] - action['cur_jd_type_set']).apply(find_len_set) + action_feats[\n",
    "                    'feat_cur_type_job_key_len'] + 0.0)\n",
    "\n",
    "    #About salary\n",
    "    action_feats['feat_desire_jd_salary'] = action['desire_jd_salary_id']\n",
    "    action_feats['feat_cur_salary_id'] =action['cur_salary_id']\n",
    "    action_feats['feat_desire_cur_salary'] = action['desire_jd_salary_id'] - action['cur_salary_id']\n",
    "    action_feats['feat_desire_cur_salary_ratio'] = (action['desire_jd_salary_id'] - action['cur_salary_id'])/(action['cur_salary_id'] + 0.0)\n",
    "    action_feats['feat_cur_desire_salary_ratio'] = (action['desire_jd_salary_id'] - action['cur_salary_id'])/(action['desire_jd_salary_id'] + 0.0)\n",
    "    action_feats['feat_desire_job_max_salary'] = action['desire_jd_max_salary'] - action['max_salary']\n",
    "    action_feats['feat_desire_job_min_salary'] = action['desire_jd_min_salary'] - action['min_salary']\n",
    "    action_feats['feat_desire_job_max_salary_ratio'] = action['desire_jd_max_salary'] / (action['max_salary'] + 0.0)\n",
    "    action_feats['feat_desire_job_min_salary_ratio'] = action['desire_jd_min_salary'] / (action['min_salary'] + 0.0)\n",
    "    action_feats['feat_cur_job_max_salary'] = action['cur_jd_max_salary'] - action['max_salary']\n",
    "    action_feats['feat_cur_job_min_salary'] = action['cur_jd_min_salary'] - action['min_salary']\n",
    "    action_feats['feat_cur_job_max_salary_ratio'] = action['cur_jd_max_salary'] / (action['max_salary'] + 0.0)\n",
    "    action_feats['feat_cur_job_min_salary_ratio'] = action['cur_jd_min_salary'] / (action['min_salary'] + 0.0)\n",
    "\n",
    "    #About degree\n",
    "    action_feats['feat_degree'] = action['cur_degree_id']\n",
    "    action_feats['feat_degree_min_edu'] = action['cur_degree_id'] - action['min_edu_level']\n",
    "    action_feats['feat_degree_min_bool'] = (action['cur_degree_id'] >= action['min_edu_level']) * 1\n",
    "    action_feats['feat_degree_min_edu_ratio'] = action['cur_degree_id'] / (action['min_edu_level'] + 0.0)\n",
    "\n",
    "    #About age and time\n",
    "    action_feats['feat_birthday'] = action['birthday']\n",
    "    action_feats['feat_work_year'] = 2019 - action['start_work_date']\n",
    "    action_feats['feat_min_years'] = action['min_years']\n",
    "    action_feats['feat_work_year_birthday_ratio'] = action_feats['feat_work_year'] / (action_feats['feat_birthday'] + 0.0)\n",
    "    action_feats['feat_work_year_min_years_gaps'] = action_feats['feat_work_year'] - action_feats['feat_min_years']\n",
    "    action_feats['feat_work_year_min_years_ratio'] = action_feats['feat_work_year'] / (action_feats['feat_min_years'] + 0.0)\n",
    "    action_feats['feat_work_year_min_years_bool'] = (action_feats['feat_work_year'] >= action_feats['feat_min_years']) * 1\n",
    "\n",
    "    action_feats['feat_start_date_duration'] = (datetime(2019, 9, 1) - action['start_date']).apply(lambda x: x.days)\n",
    "    action_feats['feat_end_date_duration'] = (datetime(2019, 9, 1) - action['end_date']).apply(lambda x: x.days)\n",
    "    action_feats['feat_end_start_date_duration'] = (action['end_date'] - action['start_date']).apply(lambda x: x.days)\n",
    "\n",
    "    #Others\n",
    "    action_feats['feat_require_nums'] = action['require_nums']\n",
    "    action_feats['feat_is_travel'] = action['is_travel']\n",
    "    action_feats['feat_job_browsed_count'] = action['browsed_count']\n",
    "    action_feats['feat_job_delivered_count'] = action['delivered_count']\n",
    "    \n",
    "    return action_feats, action\n",
    "\n",
    "def test_action_generate(raw_action):\n",
    "    return raw_action.set_index(['user_id', 'jd_no'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据处理部分\n",
    "user = clean_user(train_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "job = clean_job(train_job,train_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = train_action_generate(raw_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_feats, action = feats_generate(action, user, job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_user = clean_user(test_user)\n",
    "pred_job = job\n",
    "pred_action = test_action_generate(test_action)\n",
    "pred_action_feats, pred_action = feats_generate(pred_action, pred_user, pred_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型\n",
    "def cal_one(arr):\n",
    "    if np.sum(arr) == 0:\n",
    "        #raise ValueError('Data do not contain positive point!')\n",
    "        return 0\n",
    "    arr = np.array(arr)\n",
    "    arr_cumsum = np.cumsum(arr)\n",
    "    arr_pos = np.arange(len(arr)) + 1\n",
    "    arr_result = (arr + 0.0) * arr_cumsum / arr_pos\n",
    "    return (np.sum(arr_result)+0.0) / np.sum(arr)\n",
    "\n",
    "\n",
    "def my_score(test_true, test_pred):\n",
    "    '''\n",
    "    :param result_true: DataFrame['user_id', 'job_id', 'delivered', 'satisfied']\n",
    "    :param result_pred: DataFrame ['user_id', 'job_id', 'score']\n",
    "    :return:\n",
    "    '''\n",
    "    result = pd.merge(left=test_pred, right=test_true, on=['user_id', 'job_id'], how='left')\n",
    "    result.sort_values(['user_id', 'score'], ascending=False, inplace=True)\n",
    "    score_delivered = result.groupby('user_id')['delivered'].apply(lambda x: cal_one(x))\n",
    "    score_satisfied = result.groupby('user_id')['satisfied'].apply(lambda x: cal_one(x))\n",
    "    score = result.groupby('user_id')[['user_id']].count()\n",
    "    score['score_delivered'] = score_delivered\n",
    "    score['score_satisfied'] = score_satisfied\n",
    "    score['score'] = score['score_delivered'] * 0.3 + score['score_delivered'] * 0.7\n",
    "    return score['score'].mean()\n",
    "\n",
    "\n",
    "def cv_test_model(model, action_feats, kfold=4):\n",
    "    data_count = action_feats.shape[0]\n",
    "    fold_count = data_count / kfold\n",
    "    fold_dict, test_data_list, train_data_list, train_score, test_score = {}, [], [], [], []\n",
    "    for i in range(kfold):\n",
    "        fold_dict[i] = [i * fold_count, (i+1) * fold_count]\n",
    "    for i in range(kfold):\n",
    "        test_data = action_feats.iloc[int(fold_dict[i][0]):int(fold_dict[i][1]), :].copy()\n",
    "        train_data = action_feats.drop(index=test_data.index).copy()\n",
    "        test_data_list.append(test_data)\n",
    "        train_data_list.append(train_data)\n",
    "    for i in range(kfold):\n",
    "        print ('---%dth fold start---' % i)\n",
    "        train_data = train_data_list[i]\n",
    "        test_data = test_data_list[i]\n",
    "        model.fit(train_data.drop(columns=['y', 'delivered', 'satisfied']).values, train_data['y'].values)\n",
    "\n",
    "        train_pred_y = model.predict(train_data.drop(columns=['y', 'delivered', 'satisfied']).values)\n",
    "        train_true = train_data[['delivered', 'satisfied']].reset_index()\n",
    "        train_true.columns = ['user_id', 'job_id', 'delivered', 'satisfied']\n",
    "        train_pred = train_data[[]].reset_index()\n",
    "        train_pred['y'] = train_pred_y\n",
    "        train_pred.columns = ['user_id', 'job_id', 'score']\n",
    "        train_score.append(my_score(train_true, train_pred))\n",
    "\n",
    "        y = model.predict(test_data.drop(columns=['y', 'delivered', 'satisfied']).values)\n",
    "        test_true = test_data[['delivered', 'satisfied']].reset_index()\n",
    "        test_true.columns = ['user_id', 'job_id', 'delivered', 'satisfied']\n",
    "        test_pred = test_data[[]].reset_index()\n",
    "        test_pred['score'] = y\n",
    "        test_pred.columns = ['user_id', 'job_id', 'score']\n",
    "        test_score.append(my_score(test_true, test_pred))\n",
    "    return train_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---0th fold start---\n",
      "---1th fold start---\n",
      "---2th fold start---\n",
      "---3th fold start---\n"
     ]
    }
   ],
   "source": [
    "# 交叉验证\n",
    "params = {'subsample': 1, 'colsample_bytree': 1, 'gamma': 0.7, 'learning_rate': 0.1, 'max_depth': 4,\n",
    "          'min_child_weight': 4, 'n_estimators': 100, 'n_jobs': 4, 'random_state': 0, 'reg_alpha': 0,\n",
    "          'reg_lambda': 1,\n",
    "          'scale_pos_weight': 1, 'silent': True}\n",
    "xgb_model = xgb.XGBRegressor(**params)\n",
    "xgb_train_score, xgb_test_score = cv_test_model(xgb_model, action_feats, kfold=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, gamma=0.7,\n",
       "       importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=4, min_child_weight=4, missing=None, n_estimators=100,\n",
       "       n_jobs=4, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 最后全部数据训练\n",
    "model = xgb.XGBRegressor(**params)\n",
    "x = action_feats.drop(columns=['y', 'delivered', 'satisfied']).values\n",
    "y = action_feats[['y']].values\n",
    "model.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测保存\n",
    "pred_x = pred_action_feats.values\n",
    "pred_y = model.predict(pred_x)\n",
    "result = pred_action_feats[[]].reset_index()\n",
    "result['y'] = pred_y\n",
    "result.sort_values(['user_id', 'y'], ascending=False, inplace=True)\n",
    "result.drop(columns=['y'], inplace=True)\n",
    "result.to_csv(path + 'result0902.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'XGBRegressor' object has no attribute 'best_params_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-3161f9dbb5f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'参数的最佳取值：{0}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'最佳模型得分:{0}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mshow_cv_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-88-3161f9dbb5f0>\u001b[0m in \u001b[0;36mshow_cv_result\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mshow_cv_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'参数的最佳取值：{0}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'最佳模型得分:{0}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mshow_cv_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'XGBRegressor' object has no attribute 'best_params_'"
     ]
    }
   ],
   "source": [
    "def show_cv_result(model):\n",
    "    print('参数的最佳取值：{0}'.format(model.best_params_))\n",
    "    print('最佳模型得分:{0}'.format(model.best_score_))\n",
    "show_cv_result(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 173315: expected 18 fields, saw 20\\n'\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.792 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---0th fold start---\n",
      "---1th fold start---\n",
      "---2th fold start---\n",
      "---3th fold start---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def explory_cate_data(data, col_name, show_min_count=10):\n",
    "    print ('Dtype of %s is %s and number of categoris is %d' % \\\n",
    "          (col_name, data[col_name].dtype, len(data[col_name].unique())))\n",
    "    print ('Category of %s are:' % col_name)\n",
    "    cate = data[col_name].unique()\n",
    "    cate.sort()\n",
    "    print (cate)\n",
    "    print ('Count of every category')\n",
    "    cate_count = data.groupby(col_name)[[col_name]].count()\n",
    "    cate_count.columns = ['count']\n",
    "    cate_count['perc'] = cate_count['count']/(cate_count['count'].sum()+0.0)\n",
    "    cate_count.sort_values('count', ascending=False, inplace=True)\n",
    "    print (cate_count[cate_count['count'] >= show_min_count])\n",
    "    return cate_count\n",
    "\n",
    "\n",
    "def set_score(df, set_name):\n",
    "    '''\n",
    "    :param df: df[set_name, delivered, satisfied]\n",
    "    :return:\n",
    "    '''\n",
    "    delivered_dict = defaultdict(lambda: 0)\n",
    "    satisfied_dict = defaultdict(lambda: 0)\n",
    "    df['delivered_satisfied_sum'] = df['delivered'] + df['satisfied']\n",
    "    df_nonzero = df.loc[df['delivered_satisfied_sum'] > 0, :]\n",
    "    for i in range(df_nonzero.shape[0]):\n",
    "        df_set = df_nonzero.iloc[i][set_name]\n",
    "        if pd.notna(df_set):\n",
    "            for content in df_set:\n",
    "                delivered_dict[content] = delivered_dict[content] + df_nonzero.iloc[i]['delivered']\n",
    "                satisfied_dict[content] = satisfied_dict[content] + df_nonzero.iloc[i]['satisfied']\n",
    "\n",
    "    delivered_df = pd.DataFrame({'id': delivered_dict.keys(),  'score': delivered_dict.values()})\n",
    "    satisfied_df = pd.DataFrame({'id': satisfied_dict.keys(),  'score': satisfied_dict.values()})\n",
    "    return delivered_df, satisfied_df\n",
    "\n",
    "\n",
    "def cal_key_grade(df, key_col_name, grade_col_name=None):\n",
    "    '''\n",
    "    :param df: df[key_col_name, grade_col_name]\n",
    "    :return: df\n",
    "    '''\n",
    "    if grade_col_name is None:\n",
    "        df['count'] = 1\n",
    "        grade_col_name = 'count'\n",
    "    df_dict = defaultdict(lambda: 0)\n",
    "    for i in range(df.shape[0]):\n",
    "        if pd.notna(df.iloc[i][key_col_name]):\n",
    "            for content in df.iloc[i][key_col_name]:\n",
    "                df_dict[content] = df_dict[content] + df.iloc[i][grade_col_name]\n",
    "    df_pd = pd.DataFrame({'key': df_dict.keys(),  'grade': df_dict.values()})\n",
    "    df_pd.sort_values('grade',  ascending=False, inplace=True)\n",
    "    return df_pd\n",
    "\n",
    "\n",
    "def get_key_list(df, key_col_name):\n",
    "    key_set = set()\n",
    "    for i in range(df.shape[0]):\n",
    "        if pd.notna(df.iloc[i][key_col_name]):\n",
    "            for content in df.iloc[i][key_col_name]:\n",
    "                key_set.add(content)\n",
    "    return list(key_set)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def find_len_set(x):\n",
    "    try:\n",
    "        l = len(x)\n",
    "    except:\n",
    "        l = 0\n",
    "    return l\n",
    "\n",
    "def union_set(x):\n",
    "    a = x[0]\n",
    "    b = x[1]\n",
    "    if pd.isna(a):\n",
    "        a = set()\n",
    "    if pd.isna(b):\n",
    "        b = set()\n",
    "    return a | b\n",
    "\n",
    "\n",
    "def get_one_hot(data, key_col_name):\n",
    "    value_list = get_key_list(data, key_col_name)\n",
    "    t1 = time()\n",
    "    result = pd.DataFrame([], index=data.index, columns=value_list)\n",
    "    result.iloc[:, :] = 0\n",
    "    data_series = data[key_col_name]\n",
    "    count = 0\n",
    "    for i in range(result.shape[0]):\n",
    "        if pd.notna(data_series.iloc[i]):\n",
    "            result.iloc[i][data_series.iloc[i]] = 1\n",
    "        if np.mod(count, 1000) == 0:\n",
    "            print (count)\n",
    "    print (time() - t1)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.tencentyun.com/pypi/simple\n",
      "Requirement already satisfied: lightgbm in /usr/local/lib/python3.5/dist-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.5/dist-packages (from lightgbm) (1.17.1)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.5/dist-packages (from lightgbm) (0.20.3)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.5/dist-packages (from lightgbm) (1.1.0)\n",
      "\u001b[33mYou are using pip version 18.1, however version 19.2.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install lightgbm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
