{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaggle event 推荐比赛\n",
    "本ipython notebook是对于[Kaggle event推荐比赛](https://www.kaggle.com/c/event-recommendation-engine-challenge)的一个参考解答，也简单展示了用分类(排序)模型完成推荐的一个思路。<br>\n",
    "总共分为4个部分：\n",
    "* 数据清洗与预处理\n",
    "* 构建特征(包括协同过滤推荐度等复杂特征)\n",
    "* 建模\n",
    "* 格式调整(使得符合Kaggle提交的格式)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 这是数据清洗与预处理\n",
    "from __future__ import division\n",
    "\n",
    "import itertools\n",
    "import cPickle\n",
    "import datetime\n",
    "import hashlib\n",
    "import locale\n",
    "import numpy as np\n",
    "import pycountry\n",
    "import scipy.io as sio\n",
    "import scipy.sparse as ss\n",
    "import scipy.spatial.distance as ssd\n",
    "\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "class DataCleaner:\n",
    "  \"\"\"\n",
    "  Common utilities for converting strings to equivalent numbers\n",
    "  or number buckets.\n",
    "  \"\"\"\n",
    "  def __init__(self):\n",
    "    # 载入 locales\n",
    "    self.localeIdMap = defaultdict(int)\n",
    "    for i, l in enumerate(locale.locale_alias.keys()):\n",
    "      self.localeIdMap[l] = i + 1\n",
    "    # 载入 countries\n",
    "    self.countryIdMap = defaultdict(int)\n",
    "    ctryIdx = defaultdict(int)\n",
    "    for i, c in enumerate(pycountry.countries):\n",
    "      self.countryIdMap[c.name.lower()] = i + 1\n",
    "      if c.name.lower() == \"usa\":\n",
    "        ctryIdx[\"US\"] = i\n",
    "      if c.name.lower() == \"canada\":\n",
    "        ctryIdx[\"CA\"] = i\n",
    "    for cc in ctryIdx.keys():\n",
    "      for s in pycountry.subdivisions.get(country_code=cc):\n",
    "        self.countryIdMap[s.name.lower()] = ctryIdx[cc] + 1\n",
    "    # 载入 gender id 字典\n",
    "    self.genderIdMap = defaultdict(int, {\"male\":1, \"female\":2})\n",
    "\n",
    "  def getLocaleId(self, locstr):\n",
    "    return self.localeIdMap[locstr.lower()]\n",
    "\n",
    "  def getGenderId(self, genderStr):\n",
    "    return self.genderIdMap[genderStr]\n",
    "\n",
    "  def getJoinedYearMonth(self, dateString):\n",
    "    dttm = datetime.datetime.strptime(dateString, \"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "    return \"\".join([str(dttm.year), str(dttm.month)])\n",
    "\n",
    "  def getCountryId(self, location):\n",
    "    if (isinstance(location, str)\n",
    "        and len(location.strip()) > 0\n",
    "        and location.rfind(\"  \") > -1):\n",
    "      return self.countryIdMap[location[location.rindex(\"  \") + 2:].lower()]\n",
    "    else:\n",
    "      return 0\n",
    "\n",
    "  def getBirthYearInt(self, birthYear):\n",
    "    try:\n",
    "      return 0 if birthYear == \"None\" else int(birthYear)\n",
    "    except:\n",
    "      return 0\n",
    "\n",
    "  def getTimezoneInt(self, timezone):\n",
    "    try:\n",
    "      return int(timezone)\n",
    "    except:\n",
    "      return 0\n",
    "\n",
    "  def getFeatureHash(self, value):\n",
    "    if len(value.strip()) == 0:\n",
    "      return -1\n",
    "    else:\n",
    "      return int(hashlib.sha224(value).hexdigest()[0:4], 16)\n",
    "\n",
    "  def getFloatValue(self, value):\n",
    "    if len(value.strip()) == 0:\n",
    "      return 0.0\n",
    "    else:\n",
    "      return float(value)\n",
    "\n",
    "\n",
    "class ProgramEntities:\n",
    "  \"\"\"\n",
    "  我们只关心train和test中出现的user和event，因此重点处理这部分关联数据\n",
    "  \"\"\"\n",
    "  def __init__(self):\n",
    "    # 统计训练集中有多少独立的用户的events\n",
    "    uniqueUsers = set()\n",
    "    uniqueEvents = set()\n",
    "    eventsForUser = defaultdict(set)\n",
    "    usersForEvent = defaultdict(set)\n",
    "    for filename in [\"train.csv\", \"test.csv\"]:\n",
    "      f = open(filename, 'rb')\n",
    "      f.readline().strip().split(\",\")\n",
    "      for line in f:\n",
    "        cols = line.strip().split(\",\")\n",
    "        uniqueUsers.add(cols[0])\n",
    "        uniqueEvents.add(cols[1])\n",
    "        eventsForUser[cols[0]].add(cols[1])\n",
    "        usersForEvent[cols[1]].add(cols[0])\n",
    "      f.close()\n",
    "    self.userEventScores = ss.dok_matrix((len(uniqueUsers), len(uniqueEvents)))\n",
    "    self.userIndex = dict()\n",
    "    self.eventIndex = dict()\n",
    "    for i, u in enumerate(uniqueUsers):\n",
    "      self.userIndex[u] = i\n",
    "    for i, e in enumerate(uniqueEvents):\n",
    "      self.eventIndex[e] = i\n",
    "    ftrain = open(\"train.csv\", 'rb')\n",
    "    ftrain.readline()\n",
    "    for line in ftrain:\n",
    "      cols = line.strip().split(\",\")\n",
    "      i = self.userIndex[cols[0]]\n",
    "      j = self.eventIndex[cols[1]]\n",
    "      self.userEventScores[i, j] = int(cols[4]) - int(cols[5])\n",
    "    ftrain.close()\n",
    "    sio.mmwrite(\"PE_userEventScores\", self.userEventScores)\n",
    "    # 为了防止不必要的计算，我们找出来所有关联的用户 或者 关联的event\n",
    "    # 所谓的关联用户，指的是至少在同一个event上有行为的用户pair\n",
    "    # 关联的event指的是至少同一个user有行为的event pair\n",
    "    self.uniqueUserPairs = set()\n",
    "    self.uniqueEventPairs = set()\n",
    "    for event in uniqueEvents:\n",
    "      users = usersForEvent[event]\n",
    "      if len(users) > 2:\n",
    "        self.uniqueUserPairs.update(itertools.combinations(users, 2))\n",
    "    for user in uniqueUsers:\n",
    "      events = eventsForUser[user]\n",
    "      if len(events) > 2:\n",
    "        self.uniqueEventPairs.update(itertools.combinations(events, 2))\n",
    "    cPickle.dump(self.userIndex, open(\"PE_userIndex.pkl\", 'wb'))\n",
    "    cPickle.dump(self.eventIndex, open(\"PE_eventIndex.pkl\", 'wb'))\n",
    "      \n",
    "\n",
    "class Users:\n",
    "  \"\"\"\n",
    "  构建 user/user 相似度矩阵\n",
    "  \"\"\"\n",
    "  def __init__(self, programEntities, sim=ssd.correlation):\n",
    "    cleaner = DataCleaner()\n",
    "    nusers = len(programEntities.userIndex.keys())\n",
    "    fin = open(\"users.csv\", 'rb')\n",
    "    colnames = fin.readline().strip().split(\",\")\n",
    "    self.userMatrix = ss.dok_matrix((nusers, len(colnames) - 1))\n",
    "    for line in fin:\n",
    "      cols = line.strip().split(\",\")\n",
    "      # 只考虑train.csv中出现的用户\n",
    "      if programEntities.userIndex.has_key(cols[0]):\n",
    "        i = programEntities.userIndex[cols[0]]\n",
    "        self.userMatrix[i, 0] = cleaner.getLocaleId(cols[1])\n",
    "        self.userMatrix[i, 1] = cleaner.getBirthYearInt(cols[2])\n",
    "        self.userMatrix[i, 2] = cleaner.getGenderId(cols[3])\n",
    "        self.userMatrix[i, 3] = cleaner.getJoinedYearMonth(cols[4])\n",
    "        self.userMatrix[i, 4] = cleaner.getCountryId(cols[5])\n",
    "        self.userMatrix[i, 5] = cleaner.getTimezoneInt(cols[6])\n",
    "    fin.close()\n",
    "    # 归一化用户矩阵\n",
    "    self.userMatrix = normalize(self.userMatrix, norm=\"l1\", axis=0, copy=False)\n",
    "    sio.mmwrite(\"US_userMatrix\", self.userMatrix)\n",
    "    # 计算用户相似度矩阵，之后会用到\n",
    "    self.userSimMatrix = ss.dok_matrix((nusers, nusers))\n",
    "    for i in range(0, nusers):\n",
    "      self.userSimMatrix[i, i] = 1.0\n",
    "    for u1, u2 in programEntities.uniqueUserPairs:\n",
    "      i = programEntities.userIndex[u1]\n",
    "      j = programEntities.userIndex[u2]\n",
    "      if not self.userSimMatrix.has_key((i, j)):\n",
    "        usim = sim(self.userMatrix.getrow(i).todense(),\n",
    "          self.userMatrix.getrow(j).todense())\n",
    "        self.userSimMatrix[i, j] = usim\n",
    "        self.userSimMatrix[j, i] = usim\n",
    "    sio.mmwrite(\"US_userSimMatrix\", self.userSimMatrix)\n",
    "\n",
    "\n",
    "class UserFriends:\n",
    "  \"\"\"\n",
    "  找出某用户的那些朋友，想法非常简单\n",
    "  1)如果你有更多的朋友，可能你性格外向，更容易参加各种活动\n",
    "  2)如果你朋友会参加某个活动，可能你也会跟随去参加一下\n",
    "  \"\"\"\n",
    "  def __init__(self, programEntities):\n",
    "    nusers = len(programEntities.userIndex.keys())\n",
    "    self.numFriends = np.zeros((nusers))\n",
    "    self.userFriends = ss.dok_matrix((nusers, nusers))\n",
    "    fin = open(\"user_friends.csv\", 'rb')\n",
    "    fin.readline()                # skip header\n",
    "    ln = 0\n",
    "    for line in fin:\n",
    "      if ln % 200 == 0:\n",
    "        print \"Loading line: \", ln\n",
    "      cols = line.strip().split(\",\")\n",
    "      user = cols[0]\n",
    "      if programEntities.userIndex.has_key(user):\n",
    "        friends = cols[1].split(\" \")\n",
    "        i = programEntities.userIndex[user]\n",
    "        self.numFriends[i] = len(friends)\n",
    "        for friend in friends:\n",
    "          if programEntities.userIndex.has_key(friend):\n",
    "            j = programEntities.userIndex[friend]\n",
    "            # the objective of this score is to infer the degree to\n",
    "            # and direction in which this friend will influence the\n",
    "            # user's decision, so we sum the user/event score for\n",
    "            # this user across all training events.\n",
    "            eventsForUser = programEntities.userEventScores.getrow(j).todense()\n",
    "            score = eventsForUser.sum() / np.shape(eventsForUser)[1]\n",
    "            self.userFriends[i, j] += score\n",
    "            self.userFriends[j, i] += score\n",
    "      ln += 1\n",
    "    fin.close()\n",
    "    # 归一化数组\n",
    "    sumNumFriends = self.numFriends.sum(axis=0)\n",
    "    self.numFriends = self.numFriends / sumNumFriends\n",
    "    sio.mmwrite(\"UF_numFriends\", np.matrix(self.numFriends))\n",
    "    self.userFriends = normalize(self.userFriends, norm=\"l1\", axis=0, copy=False)\n",
    "    sio.mmwrite(\"UF_userFriends\", self.userFriends)\n",
    "\n",
    "\n",
    "class Events:\n",
    "  \"\"\"\n",
    "  构建event-event相似度，注意这里有2种相似度：\n",
    "  1）由用户-event行为，类似协同过滤算出的相似度\n",
    "  2）由event本身的内容(event信息)计算出的event-event相似度\n",
    "  \"\"\"\n",
    "  def __init__(self, programEntities, psim=ssd.correlation, csim=ssd.cosine):\n",
    "    cleaner = DataCleaner()\n",
    "    fin = open(\"events.csv\", 'rb')\n",
    "    fin.readline() # skip header\n",
    "    nevents = len(programEntities.eventIndex.keys())\n",
    "    self.eventPropMatrix = ss.dok_matrix((nevents, 7))\n",
    "    self.eventContMatrix = ss.dok_matrix((nevents, 100))\n",
    "    ln = 0\n",
    "    for line in fin.readlines():\n",
    "#      if ln > 10:\n",
    "#        break\n",
    "      cols = line.strip().split(\",\")\n",
    "      eventId = cols[0]\n",
    "      if programEntities.eventIndex.has_key(eventId):\n",
    "        i = programEntities.eventIndex[eventId]\n",
    "        self.eventPropMatrix[i, 0] = cleaner.getJoinedYearMonth(cols[2]) # start_time\n",
    "        self.eventPropMatrix[i, 1] = cleaner.getFeatureHash(cols[3]) # city\n",
    "        self.eventPropMatrix[i, 2] = cleaner.getFeatureHash(cols[4]) # state\n",
    "        self.eventPropMatrix[i, 3] = cleaner.getFeatureHash(cols[5]) # zip\n",
    "        self.eventPropMatrix[i, 4] = cleaner.getFeatureHash(cols[6]) # country\n",
    "        self.eventPropMatrix[i, 5] = cleaner.getFloatValue(cols[7]) # lat\n",
    "        self.eventPropMatrix[i, 6] = cleaner.getFloatValue(cols[8]) # lon\n",
    "        for j in range(9, 109):\n",
    "          self.eventContMatrix[i, j-9] = cols[j]\n",
    "        ln += 1\n",
    "    fin.close()\n",
    "    self.eventPropMatrix = normalize(self.eventPropMatrix,\n",
    "        norm=\"l1\", axis=0, copy=False)\n",
    "    sio.mmwrite(\"EV_eventPropMatrix\", self.eventPropMatrix)\n",
    "    self.eventContMatrix = normalize(self.eventContMatrix,\n",
    "        norm=\"l1\", axis=0, copy=False)\n",
    "    sio.mmwrite(\"EV_eventContMatrix\", self.eventContMatrix)\n",
    "    # calculate similarity between event pairs based on the two matrices    \n",
    "    self.eventPropSim = ss.dok_matrix((nevents, nevents))\n",
    "    self.eventContSim = ss.dok_matrix((nevents, nevents))\n",
    "    for e1, e2 in programEntities.uniqueEventPairs:\n",
    "      i = programEntities.eventIndex[e1]\n",
    "      j = programEntities.eventIndex[e2]\n",
    "      if not self.eventPropSim.has_key((i,j)):\n",
    "        epsim = psim(self.eventPropMatrix.getrow(i).todense(),\n",
    "          self.eventPropMatrix.getrow(j).todense())\n",
    "        self.eventPropSim[i, j] = epsim\n",
    "        self.eventPropSim[j, i] = epsim\n",
    "      if not self.eventContSim.has_key((i,j)):\n",
    "        ecsim = csim(self.eventContMatrix.getrow(i).todense(),\n",
    "          self.eventContMatrix.getrow(j).todense())\n",
    "        self.eventContSim[i, j] = epsim\n",
    "        self.eventContSim[j, i] = epsim\n",
    "    sio.mmwrite(\"EV_eventPropSim\", self.eventPropSim)\n",
    "    sio.mmwrite(\"EV_eventContSim\", self.eventContSim)\n",
    "\n",
    "\n",
    "class EventAttendees():\n",
    "  \"\"\"\n",
    "  统计某个活动，参加和不参加的人数，从而为活动活跃度做准备\n",
    "  \"\"\"\n",
    "  def __init__(self, programEvents):\n",
    "    nevents = len(programEvents.eventIndex.keys())\n",
    "    self.eventPopularity = ss.dok_matrix((nevents, 1))\n",
    "    f = open(\"event_attendees.csv\", 'rb')\n",
    "    f.readline() # skip header\n",
    "    for line in f:\n",
    "      cols = line.strip().split(\",\")\n",
    "      eventId = cols[0]\n",
    "      if programEvents.eventIndex.has_key(eventId):\n",
    "        i = programEvents.eventIndex[eventId]\n",
    "        self.eventPopularity[i, 0] = \\\n",
    "          len(cols[1].split(\" \")) - len(cols[4].split(\" \"))\n",
    "    f.close()\n",
    "    self.eventPopularity = normalize(self.eventPopularity, norm=\"l1\",\n",
    "      axis=0, copy=False)\n",
    "    sio.mmwrite(\"EA_eventPopularity\", self.eventPopularity)\n",
    "\n",
    "\n",
    "def main():\n",
    "  \"\"\"\n",
    "  Generate all the matrices and data structures required for further\n",
    "  calculations.\n",
    "  \"\"\"\n",
    "  print \"calculating program entities...\"\n",
    "  pe = ProgramEntities()\n",
    "  print \"calculating user metrics...\"\n",
    "  Users(pe)\n",
    "  print \"calculating user friend metrics...\"\n",
    "  UserFriends(pe)\n",
    "  print \"calculating event metrics...\"\n",
    "  Events(pe)\n",
    "  print \"calculating event popularity metrics...\"\n",
    "  EventAttendees(pe)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 这是构建特征部分\n",
    "from __future__ import division\n",
    "\n",
    "import cPickle\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "\n",
    "class DataRewriter:\n",
    "  def __init__(self):\n",
    "    self.userIndex = cPickle.load(open(\"PE_userIndex.pkl\", 'rb'))\n",
    "    self.eventIndex = cPickle.load(open(\"PE_eventIndex.pkl\", 'rb'))\n",
    "    self.userEventScores = sio.mmread(\"PE_userEventScores\").todense()\n",
    "    self.userSimMatrix = sio.mmread(\"US_userSimMatrix\").todense()\n",
    "    self.eventPropSim = sio.mmread(\"EV_eventPropSim\").todense()\n",
    "    self.eventContSim = sio.mmread(\"EV_eventContSim\").todense()\n",
    "    self.numFriends = sio.mmread(\"UF_numFriends\")\n",
    "    self.userFriends = sio.mmread(\"UF_userFriends\").todense()\n",
    "    self.eventPopularity = sio.mmread(\"EA_eventPopularity\").todense()\n",
    "    \n",
    "  def userReco(self, userId, eventId):\n",
    "    \"\"\"\n",
    "    根据User-based协同过滤，得到event的推荐度\n",
    "    for item i\n",
    "      for every other user v that has a preference for i\n",
    "        compute similarity s between u and v\n",
    "        incorporate v's preference for i weighted by s into running aversge\n",
    "    return top items ranked by weighted average\n",
    "    \"\"\"\n",
    "    i = self.userIndex[userId]\n",
    "    j = self.eventIndex[eventId]\n",
    "    vs = self.userEventScores[:, j]\n",
    "    sims = self.userSimMatrix[i, :]\n",
    "    prod = sims * vs\n",
    "    try:\n",
    "      return prod[0, 0] - self.userEventScores[i, j]\n",
    "    except IndexError:\n",
    "      return 0\n",
    "\n",
    "  def eventReco(self, userId, eventId):\n",
    "    \"\"\"\n",
    "    根据基于物品的协同过滤，得到Event的推荐度\n",
    "    for item i \n",
    "      for every item j tht u has a preference for\n",
    "        compute similarity s between i and j\n",
    "        add u's preference for j weighted by s to a running average\n",
    "    return top items, ranked by weighted average\n",
    "    \"\"\"\n",
    "    i = self.userIndex[userId]\n",
    "    j = self.eventIndex[eventId]\n",
    "    js = self.userEventScores[i, :]\n",
    "    psim = self.eventPropSim[:, j]\n",
    "    csim = self.eventContSim[:, j]\n",
    "    pprod = js * psim\n",
    "    cprod = js * csim\n",
    "    pscore = 0\n",
    "    cscore = 0\n",
    "    try:\n",
    "      pscore = pprod[0, 0] - self.userEventScores[i, j]\n",
    "    except IndexError:\n",
    "      pass\n",
    "    try:\n",
    "      cscore = cprod[0, 0] - self.userEventScores[i, j]\n",
    "    except IndexError:\n",
    "      pass\n",
    "    return pscore, cscore\n",
    "\n",
    "  def userPop(self, userId):\n",
    "    \"\"\"\n",
    "    基于用户的朋友个数来推断用户的社交程度\n",
    "    Measures user popularity by number of friends a user has. People\n",
    "    with more friends tend to be outgoing and are more likely to go\n",
    "    to events\n",
    "    \"\"\"\n",
    "    if self.userIndex.has_key(userId):\n",
    "      i = self.userIndex[userId]\n",
    "      try:\n",
    "        return self.numFriends[0, i]\n",
    "      except IndexError:\n",
    "        return 0\n",
    "    else:\n",
    "      return 0\n",
    "\n",
    "  def friendInfluence(self, userId):\n",
    "    \"\"\"\n",
    "    朋友对用户的影响\n",
    "    Measures friends influence by the friends who are known (from the\n",
    "    training set) to go or not go to an event. The average of scores across\n",
    "    all friends of the user is the influence score.\n",
    "    \"\"\"\n",
    "    nusers = np.shape(self.userFriends)[1]\n",
    "    i = self.userIndex[userId]\n",
    "    return (self.userFriends[i, :].sum(axis=0) / nusers)[0,0]\n",
    "\n",
    "  def eventPop(self, eventId):\n",
    "    \"\"\"\n",
    "    本活动本身的热度\n",
    "    Measures event popularity by the number attending and not attending.\n",
    "    \"\"\"\n",
    "    i = self.eventIndex[eventId]\n",
    "    return self.eventPopularity[i, 0]\n",
    "\n",
    "  def rewriteData(self, start=1, train=True, header=True):\n",
    "    \"\"\"\n",
    "    生成新的训练数据，用于分类器分类使用\n",
    "    Create new features based on various recommender scores. This\n",
    "    is so we can figure out what weights to use for each recommender's\n",
    "    scores.\n",
    "    \"\"\"\n",
    "    fn = \"train.csv\" if train else \"test.csv\"\n",
    "    fin = open(fn, 'rb')\n",
    "    fout = open(\"../NewData/\" + fn, 'wb')\n",
    "    # write output header\n",
    "    if header:\n",
    "      ocolnames = [\"invited\", \"user_reco\", \"evt_p_reco\",\n",
    "        \"evt_c_reco\", \"user_pop\", \"frnd_infl\", \"evt_pop\"]\n",
    "      if train:\n",
    "        ocolnames.append(\"interested\")\n",
    "        ocolnames.append(\"not_interested\")\n",
    "      fout.write(\",\".join(ocolnames) + \"\\n\")\n",
    "    ln = 0\n",
    "    for line in fin:\n",
    "      ln += 1\n",
    "      if ln < start:\n",
    "        continue\n",
    "      cols = line.strip().split(\",\")\n",
    "      userId = cols[0]\n",
    "      eventId = cols[1]\n",
    "      invited = cols[2]\n",
    "      print \"%s:%d (userId, eventId)=(%s, %s)\" % (fn, ln, userId, eventId)\n",
    "      user_reco = self.userReco(userId, eventId)\n",
    "      evt_p_reco, evt_c_reco = self.eventReco(userId, eventId)\n",
    "      user_pop = self.userPop(userId)\n",
    "      frnd_infl = self.friendInfluence(userId)\n",
    "      evt_pop = self.eventPop(eventId)\n",
    "      ocols = [invited, user_reco, evt_p_reco,\n",
    "        evt_c_reco, user_pop, frnd_infl, evt_pop]\n",
    "      if train:\n",
    "        ocols.append(cols[4]) # interested\n",
    "        ocols.append(cols[5]) # not_interested\n",
    "      fout.write(\",\".join(map(lambda x: str(x), ocols)) + \"\\n\")\n",
    "    fin.close()\n",
    "    fout.close()\n",
    "\n",
    "  def rewriteTrainingSet(self):\n",
    "    self.rewriteData(True)\n",
    "\n",
    "  def rewriteTestSet(self):\n",
    "    self.rewriteData(False)\n",
    "\n",
    "# When running with cython, the actual class will be converted to a .so\n",
    "# file, and the following code (along with the commented out import below)\n",
    "# will need to be put into another .py and this should be run.\n",
    "\n",
    "#import CRegressionData as rd\n",
    "\n",
    "def main():\n",
    "  dr = DataRewriter()\n",
    "  print \"rewriting training data...\"\n",
    "  dr.rewriteData(train=True, start=2, header=False)\n",
    "  print \"rewriting test data...\"\n",
    "  dr.rewriteData(train=False, start=2, header=True)\n",
    "  \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "  main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 建模与预测\n",
    "from __future__ import division\n",
    "\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "def train():\n",
    "  \"\"\"\n",
    "  训练分类器，target为1(感兴趣)，或者是0(不感兴趣)\n",
    "  Trains a classifier on the entire (modified) training dataset.\n",
    "  Since our objective is to predict only interested users, we\n",
    "  only consider the outcome 1=interested and 0=not.\n",
    "  \"\"\"\n",
    "  trainDf = pd.read_csv(\"../NewData/train.csv\")\n",
    "  X = np.matrix(pd.DataFrame(trainDf, index=None,\n",
    "    columns=[\"invited\", \"user_reco\", \"evt_p_reco\", \"evt_c_reco\",\n",
    "    \"user_pop\", \"frnd_infl\", \"evt_pop\"]))\n",
    "  y = np.array(trainDf.interested)\n",
    "  clf = SGDClassifier(loss=\"log\", penalty=\"l2\")\n",
    "  clf.fit(X, y)\n",
    "  return clf\n",
    "\n",
    "def validate():\n",
    "  \"\"\"\n",
    "  10折的交叉验证\n",
    "  Runs a 10-fold cross validation on the classifier, reporting\n",
    "  accuracy.\n",
    "  \"\"\"\n",
    "  trainDf = pd.read_csv(\"../NewData/train.csv\")\n",
    "  X = np.matrix(pd.DataFrame(trainDf, index=None,\n",
    "    columns=[\"invited\", \"user_reco\", \"evt_p_reco\", \"evt_c_reco\",\n",
    "    \"user_pop\", \"frnd_infl\", \"evt_pop\"]))\n",
    "  y = np.array(trainDf.interested)\n",
    "  nrows = len(trainDf)\n",
    "  kfold = KFold(nrows, 10)\n",
    "  avgAccuracy = 0\n",
    "  run = 0\n",
    "  for train, test in kfold:\n",
    "    Xtrain, Xtest, ytrain, ytest = X[train], X[test], y[train], y[test]\n",
    "    clf = SGDClassifier(loss=\"log\", penalty=\"l2\")\n",
    "    clf.fit(Xtrain, ytrain)\n",
    "    accuracy = 0\n",
    "    ntest = len(ytest)\n",
    "    for i in range(0, ntest):\n",
    "      yt = clf.predict(Xtest[i, :])\n",
    "      if yt == ytest[i]:\n",
    "        accuracy += 1\n",
    "    accuracy = accuracy / ntest\n",
    "    print \"accuracy (run %d): %f\" % (run, accuracy)\n",
    "    avgAccuracy += accuracy\n",
    "    run += 1\n",
    "  print \"Average accuracy\", (avgAccuracy / run)\n",
    "\n",
    "def test(clf):\n",
    "  \"\"\"\n",
    "  读取test数据，用分类器完成预测\n",
    "  Reads the X values from the dataframe provided, then uses the\n",
    "  trained classifier to write an array of outcomes.\n",
    "  \"\"\"\n",
    "  origTestDf = pd.read_csv(\"../Data/test.csv\")\n",
    "  users = origTestDf.user\n",
    "  events = origTestDf.event\n",
    "  testDf = pd.read_csv(\"../NewData/test.csv\")\n",
    "  fout = open(\"../NewData/result.csv\", 'wb')\n",
    "  fout.write(\",\".join([\"user\", \"event\", \"outcome\", \"dist\"]) + \"\\n\")\n",
    "  nrows = len(testDf)\n",
    "  Xp = np.matrix(testDf)\n",
    "  yp = np.zeros((nrows, 2))\n",
    "  for i in range(0, nrows):\n",
    "    xp = Xp[i, :]\n",
    "    yp[i, 0] = clf.predict(xp)\n",
    "    yp[i, 1] = clf.decision_function(xp)\n",
    "    fout.write(\",\".join(map(lambda x: str(x), \n",
    "      [users[i], events[i], yp[i, 0], yp[i, 1]])) + \"\\n\")\n",
    "  fout.close()\n",
    "\n",
    "def main():\n",
    "#  validate()\n",
    "  clf = train()\n",
    "  test(clf)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 处理成提交结果的格式\n",
    "from __future__ import division\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def byDist(x, y):\n",
    "  return int(y[1] - x[1])\n",
    "\n",
    "def main():\n",
    "  # output file\n",
    "  fout = open(\"../NewData/final_result.csv\", 'wb')\n",
    "  fout.write(\",\".join([\"User\", \"Events\"]) + \"\\n\")\n",
    "  resultDf = pd.read_csv(\"../NewData/result.csv\")\n",
    "  # group remaining user/events\n",
    "  grouped = resultDf.groupby(\"user\")\n",
    "  for name, group in grouped:\n",
    "    user = str(name)\n",
    "    tuples = zip(list(group.event), list(group.dist), list(group.outcome))\n",
    "#    tuples = filter(lambda x: x[2]==1, tuples)\n",
    "    tuples = sorted(tuples, cmp=byDist)\n",
    "    events = \"\\\"\" + str(map(lambda x: x[0], tuples)) + \"\\\"\"\n",
    "    fout.write(\",\".join([user, events]) + \"\\n\")\n",
    "  fout.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
