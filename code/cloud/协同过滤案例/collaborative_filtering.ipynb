{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "初始化路径和变量...\n"
     ]
    }
   ],
   "source": [
    "print('初始化路径和变量...')\n",
    "names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "trainingset_file = 'data/u3.base'\n",
    "testset_file= 'data/u3.test'\n",
    "n_users = 943\n",
    "n_items = 1682\n",
    "ratings = np.zeros((n_users, n_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "载入训练集...\n",
      "数据集样例为(头5个样本):\n",
      "   user_id  item_id  rating  timestamp\n",
      "0        1        1       5  874965758\n",
      "1        1        2       3  876893171\n",
      "2        1        3       4  878542960\n",
      "3        1        4       3  876893119\n",
      "4        1        6       5  887431973\n",
      "载入数据完成.\n",
      "打分矩阵规模为 943*1682.\n",
      "训练集有效打分个数为 80000.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(trainingset_file, sep='\\t', names=names)\n",
    "print('载入训练集...')\n",
    "print('数据集样例为(头5个样本):')\n",
    "print(df.head())\n",
    "for row in df.itertuples():\n",
    "    ratings[row[1]-1, row[2]-1] = row[3]\n",
    "print('载入数据完成.')\n",
    "print('打分矩阵规模为 %d*%d.' % (n_users, n_items))\n",
    "print('训练集有效打分个数为 %d.' % len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集矩阵密度为: 5.04%\n"
     ]
    }
   ],
   "source": [
    "# 计算矩阵密度(填充度)\n",
    "def cal_sparsity():\n",
    "    sparsity = float(len(ratings.nonzero()[0]))\n",
    "    sparsity /= (ratings.shape[0] * ratings.shape[1])\n",
    "    sparsity *= 100\n",
    "    print('训练集矩阵密度为: {:4.2f}%'.format(sparsity))\n",
    "\n",
    "cal_sparsity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rmse(pred, actual):\n",
    "    '''计算预测结果的rmse'''\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    pred = pred[actual.nonzero()].flatten()\n",
    "    actual = actual[actual.nonzero()].flatten()\n",
    "    return np.sqrt(mean_squared_error(pred, actual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ 基线算法(baseline) ------\n"
     ]
    }
   ],
   "source": [
    "print('------ 基线算法(baseline) ------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cal_mean():\n",
    "    '''我们需要计算一些均值'''\n",
    "    print('计算训练集各项统计数据...')\n",
    "    print('计算总体均值，各user打分均值，各item打分均值...\\n请稍后......')\n",
    "    global all_mean, user_mean, item_mean\n",
    "    all_mean = np.mean(ratings[ratings!=0])\n",
    "    user_mean = sum(ratings.T) / sum((ratings!=0).T)\n",
    "    item_mean = sum(ratings) / sum((ratings!=0))\n",
    "    \n",
    "    user_mean_nan = '是'\n",
    "    item_mean_nan = '是'\n",
    "    if np.isnan(user_mean).any():\n",
    "        user_mean_nan = '否'\n",
    "    if np.isnan(item_mean).any():\n",
    "        item_mean_nan = '否'\n",
    "    print '是否存在User均值为NaN?', user_mean_nan\n",
    "    print '是否存在Item均值为NaN?', item_mean_nan\n",
    "    print('对NaN填充总体均值...')\n",
    "    \n",
    "    user_mean = np.where(np.isnan(user_mean), all_mean, user_mean)\n",
    "    item_mean = np.where(np.isnan(item_mean), all_mean, item_mean)\n",
    "    if np.isnan(user_mean).any():\n",
    "        user_mean_nan = '否'\n",
    "    if np.isnan(item_mean).any():\n",
    "        item_mean_nan = '否'\n",
    "    print '是否存在User均值为NaN?', user_mean_nan\n",
    "    print '是否存在Item均值为NaN?', item_mean_nan\n",
    "    print '均值计算完成，总体打分均值为 %.4f' % all_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "计算训练集各项统计数据...\n",
      "计算总体均值，各user打分均值，各item打分均值...\n",
      "请稍后......\n",
      "是否存在User均值为NaN? 是\n",
      "是否存在Item均值为NaN? 否\n",
      "对NaN填充总体均值...\n",
      "是否存在User均值为NaN? 是\n",
      "是否存在Item均值为NaN? 否\n",
      "均值计算完成，总体打分均值为 3.5311\n"
     ]
    }
   ],
   "source": [
    "cal_mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict_naive(user, item):\n",
    "    prediction = item_mean[item] + user_mean[user] - all_mean\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "载入测试集...\n",
      "测试集大小为 20000\n",
      "采用基线算法进行预测...\n",
      "测试结果的rmse为 0.9691\n"
     ]
    }
   ],
   "source": [
    "print('载入测试集...')\n",
    "test_df = pd.read_csv(testset_file, sep='\\t', names=names)\n",
    "test_df.head()\n",
    "predictions = []\n",
    "targets = []\n",
    "print('测试集大小为 %d' % len(test_df))\n",
    "print('采用基线算法进行预测...')\n",
    "for row in test_df.itertuples():\n",
    "    user, item, actual = row[1]-1, row[2]-1, row[3]\n",
    "    predictions.append(predict_naive(user, item))\n",
    "    targets.append(actual)\n",
    "\n",
    "print('测试结果的rmse为 %.4f' % rmse(np.array(predictions), np.array(targets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ item-based协同过滤算法(相似度未归一化) ------\n"
     ]
    }
   ],
   "source": [
    "print('------ item-based协同过滤算法(相似度未归一化) ------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cal_similarity(ratings, kind, epsilon=1e-9):\n",
    "    '''利用余弦距离计算相似度'''\n",
    "    '''epsilon: 防止分母为0的异常'''\n",
    "    if kind == 'user':\n",
    "        sim = ratings.dot(ratings.T) + epsilon\n",
    "    elif kind == 'item':\n",
    "        sim = ratings.T.dot(ratings) + epsilon\n",
    "    norms = np.array([np.sqrt(np.diagonal(sim))])\n",
    "    return (sim / norms / norms.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "计算相似度矩阵...\n",
      "计算完成.\n",
      "相似度矩阵样例: (item-item)\n",
      "[[ 1.     0.296  0.279  0.388  0.252  0.114  0.518  0.41   0.416  0.199]\n",
      " [ 0.296  1.     0.177  0.405  0.211  0.099  0.331  0.31   0.207  0.152]\n",
      " [ 0.279  0.177  1.     0.275  0.118  0.104  0.311  0.125  0.207  0.121]\n",
      " [ 0.388  0.405  0.275  1.     0.265  0.091  0.411  0.391  0.357  0.219]\n",
      " [ 0.252  0.211  0.118  0.265  1.     0.016  0.28   0.214  0.202  0.031]\n",
      " [ 0.114  0.099  0.104  0.091  0.016  1.     0.128  0.065  0.164  0.139]\n",
      " [ 0.518  0.331  0.311  0.411  0.28   0.128  1.     0.342  0.43   0.279]\n",
      " [ 0.41   0.31   0.125  0.391  0.214  0.065  0.342  1.     0.364  0.166]\n",
      " [ 0.416  0.207  0.207  0.357  0.202  0.164  0.43   0.364  1.     0.25 ]\n",
      " [ 0.199  0.152  0.121  0.219  0.031  0.139  0.279  0.166  0.25   1.   ]]\n"
     ]
    }
   ],
   "source": [
    "print('计算相似度矩阵...')\n",
    "user_similarity = cal_similarity(ratings, kind='user')\n",
    "item_similarity = cal_similarity(ratings, kind='item')\n",
    "print('计算完成.')\n",
    "print('相似度矩阵样例: (item-item)')\n",
    "print(np.round_(item_similarity[:10,:10], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict_itemCF(user, item, k=100):\n",
    "    '''item-based协同过滤算法,预测rating'''\n",
    "    nzero = ratings[user].nonzero()[0]\n",
    "    prediction = ratings[user, nzero].dot(item_similarity[item, nzero])\\\n",
    "                / sum(item_similarity[item, nzero])\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "载入测试集...\n",
      "测试集大小为 20000\n",
      "采用item-based协同过滤算法进行预测...\n",
      "测试结果的rmse为 1.0042\n"
     ]
    }
   ],
   "source": [
    "print('载入测试集...')\n",
    "test_df = pd.read_csv(testset_file, sep='\\t', names=names)\n",
    "test_df.head()\n",
    "predictions = []\n",
    "targets = []\n",
    "print('测试集大小为 %d' % len(test_df))\n",
    "print('采用item-based协同过滤算法进行预测...')\n",
    "for row in test_df.itertuples():\n",
    "    user, item, actual = row[1]-1, row[2]-1, row[3]\n",
    "    predictions.append(predict_itemCF(user, item))\n",
    "    targets.append(actual)\n",
    "\n",
    "print('测试结果的rmse为 %.4f' % rmse(np.array(predictions), np.array(targets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ 结合基线算法的item-based协同过滤算法(相似度未归一化) ------\n"
     ]
    }
   ],
   "source": [
    "print('------ 结合基线算法的item-based协同过滤算法(相似度未归一化) ------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict_itemCF_baseline(user, item, k=100):\n",
    "    '''结合baseline的item-basedCF算法,预测rating'''\n",
    "    nzero = ratings[user].nonzero()[0]\n",
    "    baseline = item_mean + user_mean[user] - all_mean\n",
    "    prediction = (ratings[user, nzero] - baseline[nzero]).dot(item_similarity[item, nzero])\\\n",
    "                / sum(item_similarity[item, nzero]) + baseline[item]\n",
    "    return prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "载入测试集...\n",
      "测试集大小为 20000\n",
      "采用结合baseline的item-item协同过滤算法进行预测...\n",
      "测试结果的rmse为 0.9345\n"
     ]
    }
   ],
   "source": [
    "print('载入测试集...')\n",
    "test_df = pd.read_csv(testset_file, sep='\\t', names=names)\n",
    "test_df.head()\n",
    "predictions = []\n",
    "targets = []\n",
    "print('测试集大小为 %d' % len(test_df))\n",
    "print('采用结合baseline的item-item协同过滤算法进行预测...')\n",
    "for row in test_df.itertuples():\n",
    "    user, item, actual = row[1]-1, row[2]-1, row[3]\n",
    "    predictions.append(predict_itemCF_baseline(user, item))\n",
    "    targets.append(actual)\n",
    "\n",
    "print('测试结果的rmse为 %.4f' % rmse(np.array(predictions), np.array(targets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ user-based协同过滤算法(相似度未归一化) ------\n",
      "载入测试集...\n",
      "测试集大小为 20000\n",
      "采用user-user协同过滤算法进行预测...\n",
      "测试结果的rmse为 1.0133\n"
     ]
    }
   ],
   "source": [
    "print('------ user-based协同过滤算法(相似度未归一化) ------')\n",
    "\n",
    "def predict_userCF(user, item, k=100):\n",
    "    '''user-user协同过滤算法,预测rating'''\n",
    "    nzero = ratings[:,item].nonzero()[0]\n",
    "    baseline = user_mean + item_mean[item] - all_mean\n",
    "    prediction = ratings[nzero, item].dot(user_similarity[user, nzero])\\\n",
    "                / sum(user_similarity[user, nzero])\n",
    "    # 冷启动问题: 该item暂时没有评分\n",
    "    if np.isnan(prediction):\n",
    "        prediction = baseline[user]\n",
    "    return prediction\n",
    "\n",
    "print('载入测试集...')\n",
    "test_df = pd.read_csv(testset_file, sep='\\t', names=names)\n",
    "test_df.head()\n",
    "predictions = []\n",
    "targets = []\n",
    "print('测试集大小为 %d' % len(test_df))\n",
    "print('采用user-user协同过滤算法进行预测...')\n",
    "\n",
    "for row in test_df.itertuples():\n",
    "    user, item, actual = row[1]-1, row[2]-1, row[3]\n",
    "    predictions.append(predict_userCF(user, item))\n",
    "    targets.append(actual)\n",
    "\n",
    "print('测试结果的rmse为 %.4f' % rmse(np.array(predictions), np.array(targets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ 结合基线算法的的user-user协同过滤算法(相似度未归一化) ------\n",
      "载入测试集...\n",
      "测试集大小为 20000\n",
      "采用结合baseline的user-user协同过滤算法进行预测...\n",
      "测试结果的rmse为 0.9519\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('------ 结合基线算法的的user-user协同过滤算法(相似度未归一化) ------')\n",
    "\n",
    "def predict_userCF_baseline(user, item, k=100):\n",
    "    '''结合baseline的user-user协同过滤算法,预测rating'''\n",
    "    nzero = ratings[:,item].nonzero()[0]\n",
    "    baseline = user_mean + item_mean[item] - all_mean\n",
    "    prediction = (ratings[nzero, item] - baseline[nzero]).dot(user_similarity[user, nzero])\\\n",
    "                / sum(user_similarity[user, nzero]) + baseline[user]\n",
    "    if np.isnan(prediction):\n",
    "        prediction = baseline[user]\n",
    "    return prediction\n",
    "\n",
    "print('载入测试集...')\n",
    "test_df = pd.read_csv(testset_file, sep='\\t', names=names)\n",
    "test_df.head()\n",
    "predictions = []\n",
    "targets = []\n",
    "print('测试集大小为 %d' % len(test_df))\n",
    "print('采用结合baseline的user-user协同过滤算法进行预测...')\n",
    "\n",
    "for row in test_df.itertuples():\n",
    "    user, item, actual = row[1]-1, row[2]-1, row[3]\n",
    "    predictions.append(predict_userCF_baseline(user, item))\n",
    "    targets.append(actual)\n",
    "    \n",
    "print('测试结果的rmse为 %.4f' % rmse(np.array(predictions), np.array(targets)))\n",
    "print "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ 经过修正后的协同过滤 ------\n",
      "载入测试集...\n",
      "测试集大小为 20000\n",
      "采用结合baseline的item-based协同过滤算法进行预测...\n",
      "测试结果的rmse为 0.9344\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('------ 经过修正后的协同过滤 ------')\n",
    "def predict_biasCF(user, item, k=100):\n",
    "    '''结合基线算法的item-based CF算法,预测rating'''\n",
    "    nzero = ratings[user].nonzero()[0]\n",
    "    baseline = item_mean + user_mean[user] - all_mean\n",
    "    prediction = (ratings[user, nzero] - baseline[nzero]).dot(item_similarity[item, nzero])\\\n",
    "                / sum(item_similarity[item, nzero]) + baseline[item]\n",
    "    if prediction > 5:\n",
    "        prediction = 5\n",
    "    if prediction < 1:\n",
    "        prediciton = 1\n",
    "    return prediction\n",
    "\n",
    "print('载入测试集...')\n",
    "test_df = pd.read_csv(testset_file, sep='\\t', names=names)\n",
    "test_df.head()\n",
    "predictions = []\n",
    "targets = []\n",
    "print('测试集大小为 %d' % len(test_df))\n",
    "print('采用结合baseline的item-based协同过滤算法进行预测...')\n",
    "for row in test_df.itertuples():\n",
    "    user, item, actual = row[1]-1, row[2]-1, row[3]\n",
    "    predictions.append(predict_biasCF(user, item))\n",
    "    targets.append(actual)\n",
    "\n",
    "print('测试结果的rmse为 %.4f' % rmse(np.array(predictions), np.array(targets)))\n",
    "print "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Top-k协同过滤(item-based + baseline)------\n",
      "载入测试集...\n",
      "测试集大小为 20000\n",
      "采用top K协同过滤算法进行预测...\n",
      "选取的K值为20.\n",
      "测试结果的rmse为 0.9181\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('------ Top-k协同过滤(item-based + baseline)------')\n",
    "def predict_topkCF(user, item, k=10):\n",
    "    '''top-k CF算法,以item-based协同过滤为基础，结合baseline,预测rating'''\n",
    "    nzero = ratings[user].nonzero()[0]\n",
    "    baseline = item_mean + user_mean[user] - all_mean\n",
    "    choice = nzero[item_similarity[item, nzero].argsort()[::-1][:k]]\n",
    "    prediction = (ratings[user, choice] - baseline[choice]).dot(item_similarity[item, choice])\\\n",
    "                / sum(item_similarity[item, choice]) + baseline[item]\n",
    "    if prediction > 5: prediction = 5\n",
    "    if prediction < 1: prediction = 1\n",
    "    return prediction \n",
    "\n",
    "print('载入测试集...')\n",
    "test_df = pd.read_csv(testset_file, sep='\\t', names=names)\n",
    "test_df.head()\n",
    "predictions = []\n",
    "targets = []\n",
    "print('测试集大小为 %d' % len(test_df))\n",
    "print('采用top K协同过滤算法进行预测...')\n",
    "k = 20\n",
    "print('选取的K值为%d.' % k)\n",
    "for row in test_df.itertuples():\n",
    "    user, item, actual = row[1]-1, row[2]-1, row[3]\n",
    "    predictions.append(predict_topkCF(user, item, k))\n",
    "    targets.append(actual)\n",
    "\n",
    "print('测试结果的rmse为 %.4f' % rmse(np.array(predictions), np.array(targets)))\n",
    "print "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "经检验，在100k数据上，K=20为比较好的近邻取值.\n"
     ]
    }
   ],
   "source": [
    "print('经检验，在100k数据上，K=20为比较好的近邻取值.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ baseline + item-based + TopK + 归一化矩阵 ------\n"
     ]
    }
   ],
   "source": [
    "print('------ baseline + item-based + TopK + 归一化矩阵 ------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "计算归一化的相似度矩阵...\n",
      "计算完成.\n",
      "相似度矩阵样例: (item-item)\n",
      "[[ 1.     0.053  0.055  0.028  0.125  0.046  0.051  0.07   0.039  0.022]\n",
      " [ 0.053  1.     0.021  0.122  0.021 -0.007  0.052  0.109 -0.061  0.051]\n",
      " [ 0.055  0.021  1.    -0.035  0.013  0.048 -0.011 -0.003 -0.048  0.044]\n",
      " [ 0.028  0.122 -0.035  1.    -0.008 -0.028  0.053  0.087  0.028  0.036]\n",
      " [ 0.125  0.021  0.013 -0.008  1.    -0.011  0.104  0.025  0.043 -0.016]\n",
      " [ 0.046 -0.007  0.048 -0.028 -0.011  1.     0.026 -0.071  0.035  0.013]\n",
      " [ 0.051  0.052 -0.011  0.053  0.104  0.026  1.     0.051  0.143  0.025]\n",
      " [ 0.07   0.109 -0.003  0.087  0.025 -0.071  0.051  1.     0.019  0.043]\n",
      " [ 0.039 -0.061 -0.048  0.028  0.043  0.035  0.143  0.019  1.     0.005]\n",
      " [ 0.022  0.051  0.044  0.036 -0.016  0.013  0.025  0.043  0.005  1.   ]]\n"
     ]
    }
   ],
   "source": [
    "def cal_similarity_norm(ratings, kind, epsilon=1e-9):\n",
    "    '''采用归一化的指标:Pearson correlation coefficient'''\n",
    "    if kind == 'user':\n",
    "        # 对同一个user的打分归一化\n",
    "        rating_user_diff = ratings.copy()\n",
    "        for i in range(ratings.shape[0]):\n",
    "            nzero = ratings[i].nonzero()\n",
    "            rating_user_diff[i][nzero] = ratings[i][nzero] - user_mean[i]\n",
    "        sim = rating_user_diff.dot(rating_user_diff.T) + epsilon\n",
    "    elif kind == 'item':\n",
    "        # 对同一个item的打分归一化\n",
    "        rating_item_diff = ratings.copy()\n",
    "        for j in range(ratings.shape[1]):\n",
    "            nzero = ratings[:,j].nonzero()\n",
    "            rating_item_diff[:,j][nzero] = ratings[:,j][nzero] - item_mean[j]\n",
    "        sim = rating_item_diff.T.dot(rating_item_diff) + epsilon\n",
    "    norms = np.array([np.sqrt(np.diagonal(sim))])\n",
    "    return (sim / norms / norms.T)\n",
    "\n",
    "print('计算归一化的相似度矩阵...')\n",
    "user_similarity_norm = cal_similarity_norm(ratings, kind='user')\n",
    "item_similarity_norm = cal_similarity_norm(ratings, kind='item')\n",
    "print('计算完成.')\n",
    "print('相似度矩阵样例: (item-item)')\n",
    "print(np.round_(item_similarity_norm[:10,:10], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "载入测试集...\n",
      "测试集大小为 20000\n",
      "采用归一化矩阵方法，结合其它trick进行预测...\n",
      "选取的K值为13.\n",
      "测试结果的rmse为 0.9200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def predict_norm_CF(user, item, k=20):\n",
    "    '''baseline + item-based + 皮尔森归一化'''\n",
    "    nzero = ratings[user].nonzero()[0]\n",
    "    baseline = item_mean + user_mean[user] - all_mean\n",
    "    choice = nzero[item_similarity_norm[item, nzero].argsort()[::-1][:k]]\n",
    "    prediction = (ratings[user, choice] - baseline[choice]).dot(item_similarity_norm[item, choice])\\\n",
    "                / sum(item_similarity_norm[item, choice]) + baseline[item]\n",
    "    if prediction > 5: prediction = 5\n",
    "    if prediction < 1: prediction = 1\n",
    "    return prediction \n",
    "\n",
    "print('载入测试集...')\n",
    "test_df = pd.read_csv(testset_file, sep='\\t', names=names)\n",
    "test_df.head()\n",
    "predictions = []\n",
    "targets = []\n",
    "print('测试集大小为 %d' % len(test_df))\n",
    "print('采用归一化矩阵方法，结合其它trick进行预测...')\n",
    "k = 13\n",
    "print('选取的K值为%d.' % k)\n",
    "for row in test_df.itertuples():\n",
    "    user, item, actual = row[1]-1, row[2]-1, row[3]\n",
    "    predictions.append(predict_norm_CF(user, item, k))\n",
    "    targets.append(actual)\n",
    "\n",
    "print('测试结果的rmse为 %.4f' % rmse(np.array(predictions), np.array(targets)))\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('------ 测试Top K ------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
