### 无量纲处理

在进行特征选择之前，一般会先进行数据无量纲化处理，这样，表征不同属性（单位不同）的各特征之间才有可比性，如1cm 与 0.1kg 你怎么比？无量纲处理方法很多，使用不同的方法，对最终的机器学习模型会产生不同的影响。

#### min-max归一化

$$
x_{'} = \frac{x-min}{max-min}
$$

该方法是对原始数据进行线性变换，将其映射到[0,1]之间。

上式中，min是样本的最小值，max是样本的最大值。由于最大值与最小值可能是动态变化的，同时也非常容易受噪声(异常点、离群点)影响，因此一般适合小数据的场景。

```
from sklearn.preprocessing import MinMaxScaler
x = np.array([[1,-1,2],[2,0,0],[0,1,-1]])
x1 = MinMaxScaler().fit_transform(x)
```

不难发现，x1每列的值都在[0,1]之间，也就是说，该模块是按列计算的。

#### z-score标准化

z-score标准化(zero-mena normalization，0-均值标准化)方法的公式如下所示：
$$
x_{'} = \frac{x-u}{σ}
$$
上式中，*x*是原始数据，*u*是样本均值，*σ*是样本标准差。z-score标准化方法试图将原始数据集标准化成均值为0，方差为1且接近于标准正态分布的数据集。然而，一旦原始数据的分布 不 接近于一般正态分布，则标准化的效果会不好。该方法比较适合数据量大的场景。

```
from sklearn.preprocessing import StandardScaler
x = np.array([[1,2,3],[4,5,6],[1,2,1]])
x1 = StandardScaler().fit_transform(x)
```

 可以发现，x1的每一列加起来都是0，方差是1左右。注意该方法同样按列(即每个属性/特征)进行计算。

使用该类的好处在于可以保存训练集中的参数（均值、方差）直接使用其对象转换测试集数据。

```
#可以直接使用训练集对测试集数据进行转换
scaler.transform([[-1.,  1., 0.]])
```

#### Normalization(正则化)

这个方法是根据**范数**来进行 Normalization的。

*L*2范数即为欧式距离，则规则为*L*2的Normalization公式如下所示，易知，其将每行(条)数据转为相应的“单位向量”。
$$
x_{'} = \frac{x}{\sqrt{\sum_{j}^m}x_j^2}
$$

```
from sklearn import preprocessing
normalizer = preprocessing.Normalizer().fit(X)
normalizer.transform(X)
```

Normalization的过程是将每个样本缩放到单位范数,即该方法按行（维度）进行计算。

