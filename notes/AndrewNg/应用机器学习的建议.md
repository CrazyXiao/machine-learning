## 应用机器学习的建议

以预测房价为例，假如你已经完成了正则化线性回归，也就是最小化代价函数$J$的值，假如，在你得到你的学习参数以后，如果你要将你的假设函数放到一组新的房屋样本上进行测试，假如说你发现在预测房价时产生了巨大的误差，现在你的问题是要想改进这个算法，接下来应该怎么办？这就是接下来我们需要探讨的问题。

### 评估假设

将数据分成训练集和测试集，训练集用于训练模型，输出的模型用于测试集计算误差。

有以下两种方式计算误差：

1. 对于线性回归模型，我们利用测试集数据计算代价函数

2. 对于逻辑回归模型，我们除了可以利用测试数据集来计算代价函数外，还可以利用误分类的比率，对于每一个测试集样本，计算：

   ![img](../../notes/AndrewNg/images/14.png)

   然后对计算结果求平均。

### 模型选择

我们需要使用交叉验证集来帮助选择模型。使用60%的数据作为训练集，使用 20%的数据作为交叉验证集，使用20%的数据作为测试集。通过交叉验证集选出的模型，用于测试集计算误差。

### 诊断方差和偏差

当你运行一个学习算法时，如果这个算法的表现不理想，那么多半是出现两种情况：要么是偏差比较大，要么是方差比较大。换句话说，出现的情况要么是欠拟合，要么是过拟合问题。那么这两种情况，哪个和偏差有关，哪个和方差有关，或者是不是和两个都有关？

对于上面问题，我们通常会通过将训练集和交叉验证集的代价函数误差与多项式的次数绘制在同一张图表上来帮助分析：

![img](../../notes/AndrewNg/images/15.png)

**Training error:**  $J_{train}(\theta) = \frac{1}{2m}\sum_\limits{i=1}^{m}(h_{\theta}(x^{(i)})-y^{(i)})^2$

**Cross Validation error:** $J_{cv}(\theta) = \frac{1}{2m_{cv}}\sum_\limits{i=1}^{m}(h_{\theta}(x^{(i)}_{cv})-y^{(i)}_{cv})^2$

对于训练集，当 $d$ 较小时，模型拟合程度更低，误差较大；随着 $d$ 的增长，拟合程度提高，误差减小。

对于交叉验证集，当 $d$ 较小时，模型拟合程度低，误差较大；但是随着 $d$ 的增长，误差呈现先减小后增大的趋势，转折点是我们的模型开始过拟合训练数据集的时候。

如果我们的交叉验证集误差较大，我们如何判断是方差还是偏差呢？

训练集误差和交叉验证集误差近似时：偏差/欠拟合

交叉验证集误差远大于训练集误差时：方差/过拟合

### 正则化和偏差/方差

选择λ的方法为：

1. 使用训练集训练出12个不同程度正则化的模型

2. 用12个模型分别对交叉验证集计算出交叉验证误差

3. 选择得出交叉验证误差**最小**的模型

4. 运用步骤3中选出模型对测试集计算得出推广误差，我们也可以同时将训练集和交叉验证集模型的代价函数误差与λ的值绘制在一张图表上：

   ![img](../../notes/AndrewNg/images/16.png)

   当 $\lambda$ 较小时，训练集误差较小（过拟合）而交叉验证集误差较大(高方差);

   随着 $\lambda$ 的增加，训练集误差不断增加（欠拟合），而交叉验证集误差则是先减小后增加(高偏差)。

### 学习曲线

学习曲线是学习算法的一个很好的**合理检验**（**sanity check**）。学习曲线是将训练集误差和交叉验证集误差作为训练集样本数量（$m​$）的函数绘制的图表。

![img](../../notes/AndrewNg/images/21.jpg)

如上，在高偏差/欠拟合的情况下，增加数据到训练集不一定能有帮助。

![img](../../notes/AndrewNg/images/22.jpg)

如上，在高方差/过拟合的情况下，增加更多数据到训练集可能可以提高算法效果。

### 决定接下来做什么

1. 获得更多的训练样本——解决高方差
2. 尝试减少特征的数量——解决高方差
3. 尝试获得更多的特征——解决高偏差
4. 尝试增加多项式特征——解决高偏差
5. 尝试减少正则化程度λ——解决高偏差
6. 尝试增加正则化程度λ——解决高方差

